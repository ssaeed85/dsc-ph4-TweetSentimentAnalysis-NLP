{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:18.970128Z",
     "start_time": "2022-05-09T17:03:18.946590Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.max_columns = 50\n",
    "# pd.options.display.max_colwidth = 150\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate,\\\n",
    "                                    GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions/Code\n",
    "\n",
    "Much of this courtesy of lectures and Saad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:19.701223Z",
     "start_time": "2022-05-09T17:03:19.686374Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_doc(doc, stem=False):\n",
    "    \n",
    "    # Establish regex pattern, instantiate tokenizer\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    # Create tokens for doc\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    # Lowercase all words\n",
    "    doc = [word.lower() for word in doc]\n",
    "    # Remove stopwords\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "    # Stem!\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    if stem:\n",
    "        doc = [stemmer.stem(word) for word in doc]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Loading, Cleaning, and Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:20.211379Z",
     "start_time": "2022-05-09T17:03:20.168432Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../../data/judge_1377884607_tweet_product_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:20.399423Z",
     "start_time": "2022-05-09T17:03:20.382424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "8716                      Ipad everywhere. #SXSW {link}   \n",
       "8717  Wave, buzz... RT @mention We interrupt your re...   \n",
       "8718  Google's Zeiger, a physician never reported po...   \n",
       "8719  Some Verizon iPhone customers complained their...   \n",
       "8720  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "8716                            iPad   \n",
       "8717                             NaN   \n",
       "8718                             NaN   \n",
       "8719                             NaN   \n",
       "8720                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "8716                                   Positive emotion  \n",
       "8717                 No emotion toward brand or product  \n",
       "8718                 No emotion toward brand or product  \n",
       "8719                 No emotion toward brand or product  \n",
       "8720                 No emotion toward brand or product  \n",
       "\n",
       "[8721 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns for ease of use. Note that `product` is a reserved word in Python; for the second column, initially titled `emotion_in_tweet_is_directed_at`, I use `product_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:20.584563Z",
     "start_time": "2022-05-09T17:03:20.569603Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.rename(columns = {'tweet_text': 'text',\n",
    "                          'emotion_in_tweet_is_directed_at': 'product_name',\n",
    "                          'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'},\n",
    "               inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:20.803515Z",
     "start_time": "2022-05-09T17:03:20.787133Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5156\n",
       "Positive emotion                      2869\n",
       "Negative emotion                       545\n",
       "I can't tell                           151\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:20.973101Z",
     "start_time": "2022-05-09T17:03:20.949167Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8721 entries, 0 to 8720\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text          8720 non-null   object\n",
      " 1   product_name  3169 non-null   object\n",
      " 2   emotion       8721 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 204.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One null value in the `text` column. Let's check that out real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:21.316881Z",
     "start_time": "2022-05-09T17:03:21.304509Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text product_name                             emotion\n",
       "6  NaN          NaN  No emotion toward brand or product"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:21.535872Z",
     "start_time": "2022-05-09T17:03:21.518920Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.dropna(subset=['text'],\n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:21.693463Z",
     "start_time": "2022-05-09T17:03:21.680500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPad                               910\n",
      "Apple                              640\n",
      "iPad or iPhone App                 451\n",
      "Google                             412\n",
      "iPhone                             288\n",
      "Other Google product or service    282\n",
      "Android App                         78\n",
      "Android                             74\n",
      "Other Apple product or service      34\n",
      "Name: product_name, dtype: int64\n",
      "\n",
      "No emotion toward brand or product    0.591170\n",
      "Positive emotion                      0.329014\n",
      "Negative emotion                      0.062500\n",
      "I can't tell                          0.017317\n",
      "Name: emotion, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{data_df.product_name.value_counts()}\\n\")\n",
    "print(f\"{data_df.emotion.value_counts(normalize=True)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`I can't tell` makes up less than 2% of our dataset, and doesn't offer much more information in the way of word significance than the tweets labeled `No emotion toward brand or product`. It might be worth dropping records where `emotion` has been recorded as `I can't tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:22.051343Z",
     "start_time": "2022-05-09T17:03:22.033372Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        product_name  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.drop(\n",
    "    index = data_df[data_df.emotion == \"I can't tell\"].index,\n",
    "    inplace = True)\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:22.239600Z",
     "start_time": "2022-05-09T17:03:22.221612Z"
    }
   },
   "outputs": [],
   "source": [
    "sample1 = data_df.iloc[10].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:22.397311Z",
     "start_time": "2022-05-09T17:03:22.386348Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find',\n",
       " 'amp',\n",
       " 'start',\n",
       " 'impromptu',\n",
       " 'parti',\n",
       " 'sxsw',\n",
       " 'hurricaneparti',\n",
       " 'http',\n",
       " 'bit',\n",
       " 'ly',\n",
       " 'gvlrin',\n",
       " 'wait',\n",
       " 'til',\n",
       " 'android',\n",
       " 'app',\n",
       " 'come']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the custom function\n",
    "prepare_doc(doc=sample1,\n",
    "            stem=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:24.752618Z",
     "start_time": "2022-05-09T17:03:22.548377Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [wesley, g, iphon, hrs, tweet, rise, austin, d...\n",
       "1       [jessede, know, fludapp, awesom, ipad, iphon, ...\n",
       "2              [swonderlin, wait, ipad, also, sale, sxsw]\n",
       "3       [sxsw, hope, year, festiv, crashi, year, iphon...\n",
       "4       [sxtxstate, great, stuff, fri, sxsw, marissa, ...\n",
       "                              ...                        \n",
       "8716                        [ipad, everywher, sxsw, link]\n",
       "8717    [wave, buzz, rt, mention, interrupt, regular, ...\n",
       "8718    [googl, zeiger, physician, never, report, pote...\n",
       "8719    [verizon, iphon, custom, complain, time, fell,...\n",
       "8720    [rt, mention, googl, test, check, offer, sxsw,...\n",
       "Name: text, Length: 8569, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text_data = data_df['text'].apply(lambda x: prepare_doc(x, stem=True))\n",
    "\n",
    "full_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:24.859289Z",
     "start_time": "2022-05-09T17:03:24.830616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley, g, iphon, hrs, tweet, rise, austin, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessede, know, fludapp, awesom, ipad, iphon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, wait, ipad, also, sale, sxsw]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festiv, crashi, year, iphon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        product_name  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                  preprocessed_text  \n",
       "0  Negative emotion  [wesley, g, iphon, hrs, tweet, rise, austin, d...  \n",
       "1  Positive emotion  [jessede, know, fludapp, awesom, ipad, iphon, ...  \n",
       "2  Positive emotion         [swonderlin, wait, ipad, also, sale, sxsw]  \n",
       "3  Negative emotion  [sxsw, hope, year, festiv, crashi, year, iphon...  \n",
       "4  Positive emotion  [sxtxstate, great, stuff, fri, sxsw, marissa, ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['preprocessed_text'] = full_text_data\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:24.953823Z",
     "start_time": "2022-05-09T17:03:24.939861Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3     @sxsw I hope this year's festival isn't as cra...\n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "5     @teachntech00 New iPad Apps For #SpeechTherapy...\n",
       "7     #SXSW is just starting, #CTIA is around the co...\n",
       "8     Beautifully smart and simple idea RT @madebyma...\n",
       "9     Counting down the days to #sxsw plus strong Ca...\n",
       "10    Excited to meet the @samsungmobileus at #sxsw ...\n",
       "11    Find &amp; Start Impromptu Parties at #SXSW Wi...\n",
       "12    Foursquare ups the game, just in time for #SXS...\n",
       "13    Gotta love this #SXSW Google Calendar featurin...\n",
       "14    Great #sxsw ipad app from @madebymany: http://...\n",
       "15    haha, awesomely rad iPad app by @madebymany ht...\n",
       "16    Holler Gram for iPad on the iTunes App Store -...\n",
       "17    I just noticed DST is coming this weekend. How...\n",
       "18    Just added my #SXSW flights to @planely. Match...\n",
       "19    Must have #SXSW app! RT @malbonster: Lovely re...\n",
       "20    Need to buy an iPad2 while I'm in Austin at #s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['text'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:40.735425Z",
     "start_time": "2022-05-09T17:03:40.719477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [wesley, g, iphon, hrs, tweet, rise, austin, d...\n",
       "1     [jessede, know, fludapp, awesom, ipad, iphon, ...\n",
       "2            [swonderlin, wait, ipad, also, sale, sxsw]\n",
       "3     [sxsw, hope, year, festiv, crashi, year, iphon...\n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...\n",
       "5     [teachntech, new, ipad, app, speechtherapi, co...\n",
       "7     [sxsw, start, ctia, around, corner, googleio, ...\n",
       "8     [beauti, smart, simpl, idea, rt, madebymani, t...\n",
       "9     [count, day, sxsw, plus, strong, canadian, dol...\n",
       "10    [excit, meet, samsungmobileus, sxsw, show, spr...\n",
       "11    [find, amp, start, impromptu, parti, sxsw, hur...\n",
       "12    [foursquar, up, game, time, sxsw, http, j, mp,...\n",
       "13    [gotta, love, sxsw, googl, calendar, featur, t...\n",
       "14    [great, sxsw, ipad, app, madebymani, http, tin...\n",
       "15    [haha, awesom, rad, ipad, app, madebymani, htt...\n",
       "16    [holler, gram, ipad, itun, app, store, http, c...\n",
       "17    [notic, dst, come, weekend, mani, iphon, user,...\n",
       "18    [ad, sxsw, flight, plane, match, peopl, plane,...\n",
       "19    [must, sxsw, app, rt, malbonst, love, review, ...\n",
       "20    [need, buy, ipad, austin, sxsw, sure, need, q,...\n",
       "Name: preprocessed_text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['preprocessed_text'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:25.108987Z",
     "start_time": "2022-05-09T17:03:25.048443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sxsw         9116\n",
       "mention      6861\n",
       "link         4090\n",
       "ipad         2935\n",
       "rt           2925\n",
       "googl        2508\n",
       "appl         2187\n",
       "quot         1588\n",
       "iphon        1505\n",
       "store        1437\n",
       "new          1057\n",
       "app          1002\n",
       "austin        922\n",
       "amp           803\n",
       "launch        802\n",
       "circl         654\n",
       "social        637\n",
       "today         566\n",
       "android       565\n",
       "pop           558\n",
       "get           514\n",
       "open          498\n",
       "network       468\n",
       "line          440\n",
       "go            416\n",
       "via           400\n",
       "call          389\n",
       "parti         387\n",
       "free          378\n",
       "mobil         345\n",
       "sxswi         333\n",
       "come          326\n",
       "use           309\n",
       "like          309\n",
       "major         306\n",
       "win           305\n",
       "time          304\n",
       "one           301\n",
       "check         300\n",
       "day           280\n",
       "map           264\n",
       "w             261\n",
       "temporari     254\n",
       "possibl       254\n",
       "see           250\n",
       "need          238\n",
       "look          228\n",
       "design        225\n",
       "peopl         223\n",
       "make          219\n",
       "Name: preprocessed_text, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.preprocessed_text.explode().value_counts()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the total value counts, we can identify some other tokens/words that might be worth adding to our stopwords list:\n",
    "- `sxsw` & `sxswi` / `austin` - tokens that refer to setting - all tweets in corpus seem to be pulled from a South by Southwest (SXSW) festival event.\n",
    "- `rt` / `link` / `quot` - tokens that refer to Twitter interactions\n",
    "- `amp` - ampersand (&) character that was improperly transcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:03:25.201486Z",
     "start_time": "2022-05-09T17:03:25.188327Z"
    }
   },
   "outputs": [],
   "source": [
    "sw.extend([\n",
    "    'sxsw',\n",
    "    'sxswi',\n",
    "    'austin',\n",
    "    'rt',\n",
    "    'quot',\n",
    "    'mention',\n",
    "    'link',\n",
    "    'amp'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:05:24.785260Z",
     "start_time": "2022-05-09T17:05:24.764317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'No emotion toward brand or product',\n",
       "       'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "data_df['target'] = le.fit_transform(data_df['emotion'])\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T17:05:32.495157Z",
     "start_time": "2022-05-09T17:05:32.453985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley, g, iphon, hrs, tweet, rise, austin, d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessede, know, fludapp, awesom, ipad, iphon, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, wait, ipad, also, sale, sxsw]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festiv, crashi, year, iphon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[ipad, everywher, sxsw, link]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[wave, buzz, rt, mention, interrupt, regular, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[googl, zeiger, physician, never, report, pote...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[verizon, iphon, custom, complain, time, fell,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>[rt, mention, googl, test, check, offer, sxsw,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8569 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        product_name  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3     @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "...                                                 ...                 ...   \n",
       "8716                      Ipad everywhere. #SXSW {link}                iPad   \n",
       "8717  Wave, buzz... RT @mention We interrupt your re...                 NaN   \n",
       "8718  Google's Zeiger, a physician never reported po...                 NaN   \n",
       "8719  Some Verizon iPhone customers complained their...                 NaN   \n",
       "8720  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...                 NaN   \n",
       "\n",
       "                                 emotion  \\\n",
       "0                       Negative emotion   \n",
       "1                       Positive emotion   \n",
       "2                       Positive emotion   \n",
       "3                       Negative emotion   \n",
       "4                       Positive emotion   \n",
       "...                                  ...   \n",
       "8716                    Positive emotion   \n",
       "8717  No emotion toward brand or product   \n",
       "8718  No emotion toward brand or product   \n",
       "8719  No emotion toward brand or product   \n",
       "8720  No emotion toward brand or product   \n",
       "\n",
       "                                      preprocessed_text  target  \n",
       "0     [wesley, g, iphon, hrs, tweet, rise, austin, d...       0  \n",
       "1     [jessede, know, fludapp, awesom, ipad, iphon, ...       2  \n",
       "2            [swonderlin, wait, ipad, also, sale, sxsw]       2  \n",
       "3     [sxsw, hope, year, festiv, crashi, year, iphon...       0  \n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...       2  \n",
       "...                                                 ...     ...  \n",
       "8716                      [ipad, everywher, sxsw, link]       2  \n",
       "8717  [wave, buzz, rt, mention, interrupt, regular, ...       1  \n",
       "8718  [googl, zeiger, physician, never, report, pote...       1  \n",
       "8719  [verizon, iphon, custom, complain, time, fell,...       1  \n",
       "8720  [rt, mention, googl, test, check, offer, sxsw,...       1  \n",
       "\n",
       "[8569 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
