{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports / Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:18.685540Z",
     "start_time": "2022-05-09T20:43:18.677908Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.options.display.max_columns = 50\n",
    "# pd.options.display.max_colwidth = 150\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate,\\\n",
    "                                    GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions/Code\n",
    "\n",
    "Courtesy of Flatiron's lecture materials, my colleague Saad, and various others - credit due to Daniel on helping me figure out the regex pattern to exclude Twitter mentions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:19.194480Z",
     "start_time": "2022-05-09T20:43:19.185384Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_doc(doc, stem=True):\n",
    "    \n",
    "    # Establish regex pattern, instantiate tokenizer\n",
    "    # The regex pattern also excludes @mentions utilizing a\n",
    "    # negative lookbehind\n",
    "    regex_token = RegexpTokenizer(r\"(?<![@A-Za-z0-9_])([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    # Create tokens for doc\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    # Lowercase all words\n",
    "    doc = [word.lower() for word in doc]\n",
    "    # Remove stopwords\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "    # Stem!\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    if stem:\n",
    "        doc = [stemmer.stem(word) for word in doc]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "\n",
    "def cv_printScores(cv_metric):\n",
    "    print('CV Results')\n",
    "    print('='*32)\n",
    "    print('Accuracy')\n",
    "    print('-'*32)\n",
    "    print(f\"Training accuracy: {cv_metric['train_accuracy'].mean():.3f}\")\n",
    "    print(f\"Test accuracy:     {cv_metric['test_accuracy'].mean():.3f}\\n\")\n",
    "    print('F-1 Score')\n",
    "    print('-'*32)\n",
    "    print(f\"Training F1 score: {cv_metric['train_f1_macro'].mean():.3f}\")\n",
    "    print(f\"Test F1 score:     {cv_metric['test_f1_macro'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Loading, Cleaning, and Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:19.657772Z",
     "start_time": "2022-05-09T20:43:19.619929Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/judge_1377884607_tweet_product_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:19.927989Z",
     "start_time": "2022-05-09T20:43:19.899808Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8721 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3     @sxsw I hope this year's festival isn't as cra...   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "...                                                 ...   \n",
       "8716                      Ipad everywhere. #SXSW {link}   \n",
       "8717  Wave, buzz... RT @mention We interrupt your re...   \n",
       "8718  Google's Zeiger, a physician never reported po...   \n",
       "8719  Some Verizon iPhone customers complained their...   \n",
       "8720  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "8716                            iPad   \n",
       "8717                             NaN   \n",
       "8718                             NaN   \n",
       "8719                             NaN   \n",
       "8720                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                      Negative emotion  \n",
       "1                                      Positive emotion  \n",
       "2                                      Positive emotion  \n",
       "3                                      Negative emotion  \n",
       "4                                      Positive emotion  \n",
       "...                                                 ...  \n",
       "8716                                   Positive emotion  \n",
       "8717                 No emotion toward brand or product  \n",
       "8718                 No emotion toward brand or product  \n",
       "8719                 No emotion toward brand or product  \n",
       "8720                 No emotion toward brand or product  \n",
       "\n",
       "[8721 rows x 3 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line of code is used to print an example tweet from the dataset; this was helpful in creating a functional regular expression pattern using outside web tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:20.195213Z",
     "start_time": "2022-05-09T20:43:20.184241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I won the iPad accessories bag! Thanks @mention #SXSW'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[666].tweet_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns for ease of use. Note that `product` is a reserved word in Python; for the second column, initially titled `emotion_in_tweet_is_directed_at`, I use `product_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:20.529946Z",
     "start_time": "2022-05-09T20:43:20.512100Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns = {'tweet_text': 'text',\n",
    "                     'emotion_in_tweet_is_directed_at': 'product_name',\n",
    "                     'is_there_an_emotion_directed_at_a_brand_or_product': 'emotion'},\n",
    "          inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for nulls..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:20.878900Z",
     "start_time": "2022-05-09T20:43:20.865491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8721 entries, 0 to 8720\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   text          8720 non-null   object\n",
      " 1   product_name  3169 non-null   object\n",
      " 2   emotion       8721 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 204.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of nulls in `product_name`, which we'll have to deal with at one point or another, and exactly *one* null value in the `text` column. Let's check that out real quick..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:21.210776Z",
     "start_time": "2022-05-09T20:43:21.192782Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text product_name                             emotion\n",
       "6  NaN          NaN  No emotion toward brand or product"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['text'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Totally empty. We can drop that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:21.529875Z",
     "start_time": "2022-05-09T20:43:21.520023Z"
    }
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['text'],\n",
    "          inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a look of how the target column (`emotion`) and the third column, `product_name`, are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:21.844242Z",
     "start_time": "2022-05-09T20:43:21.814182Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product name value counts:\n",
      "iPad                               910\n",
      "Apple                              640\n",
      "iPad or iPhone App                 451\n",
      "Google                             412\n",
      "iPhone                             288\n",
      "Other Google product or service    282\n",
      "Android App                         78\n",
      "Android                             74\n",
      "Other Apple product or service      34\n",
      "Name: product_name, dtype: int64\n",
      "--------------------------------\n",
      "Emotion value counts:\n",
      "No emotion toward brand or product    5155\n",
      "Positive emotion                      2869\n",
      "Negative emotion                       545\n",
      "I can't tell                           151\n",
      "Name: emotion, dtype: int64\n",
      "--------------------------------\n",
      "Emotion value counts (normalized):\n",
      "No emotion toward brand or product    0.591170\n",
      "Positive emotion                      0.329014\n",
      "Negative emotion                      0.062500\n",
      "I can't tell                          0.017317\n",
      "Name: emotion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Product name value counts:\\n{df.product_name.value_counts()}\")\n",
    "print('-' * 32)\n",
    "print(f\"Emotion value counts:\\n{df.emotion.value_counts()}\")\n",
    "print('-' * 32)\n",
    "print(f\"Emotion value counts (normalized):\\n{df.emotion.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`I can't tell` makes up less than 2% of our dataset, and doesn't offer much more information in the way of word significance than the tweets labeled `No emotion toward brand or product`. It might be worth dropping records where `emotion` has been recorded as `I can't tell`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:22.188802Z",
     "start_time": "2022-05-09T20:43:22.171410Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        product_name  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(\n",
    "    index = df[df.emotion == \"I can't tell\"].index,\n",
    "    inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:22.446493Z",
     "start_time": "2022-05-09T20:43:22.431755Z"
    }
   },
   "outputs": [],
   "source": [
    "sample1 = df.iloc[10].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:22.678747Z",
     "start_time": "2022-05-09T20:43:22.664913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'find amp start impromptu parti sxsw http bit ly gvlrin wait til android app come'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the custom function from up top\n",
    "prepare_doc(doc=sample1,\n",
    "            stem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:24.914115Z",
     "start_time": "2022-05-09T20:43:22.915614Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       iphon hrs tweet rise dead need upgrad plugin s...\n",
       "1       know awesom ipad iphon app like appreci design...\n",
       "2                                wait ipad also sale sxsw\n",
       "3             hope year festiv crashi year iphon app sxsw\n",
       "4       great stuff fri sxsw marissa mayer googl tim r...\n",
       "                              ...                        \n",
       "8716                             ipad everywher sxsw link\n",
       "8717    wave buzz rt interrupt regular schedul sxsw ge...\n",
       "8718    googl zeiger physician never report potenti ae...\n",
       "8719    verizon iphon custom complain time fell back h...\n",
       "8720                  rt googl test check offer sxsw link\n",
       "Name: text, Length: 8569, dtype: object"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_text = df['text'].apply(lambda x: prepare_doc(x, stem=True))\n",
    "\n",
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:25.152643Z",
     "start_time": "2022-05-09T20:43:25.129372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>iphon hrs tweet rise dead need upgrad plugin s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>know awesom ipad iphon app like appreci design...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>wait ipad also sale sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festiv crashi year iphon app sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>great stuff fri sxsw marissa mayer googl tim r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        product_name  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "            emotion                                             tokens  \n",
       "0  Negative emotion  iphon hrs tweet rise dead need upgrad plugin s...  \n",
       "1  Positive emotion  know awesom ipad iphon app like appreci design...  \n",
       "2  Positive emotion                           wait ipad also sale sxsw  \n",
       "3  Negative emotion        hope year festiv crashi year iphon app sxsw  \n",
       "4  Positive emotion  great stuff fri sxsw marissa mayer googl tim r...  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'] = full_text\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:25.408222Z",
     "start_time": "2022-05-09T20:43:25.388105Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3     @sxsw I hope this year's festival isn't as cra...\n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "5     @teachntech00 New iPad Apps For #SpeechTherapy...\n",
       "7     #SXSW is just starting, #CTIA is around the co...\n",
       "8     Beautifully smart and simple idea RT @madebyma...\n",
       "9     Counting down the days to #sxsw plus strong Ca...\n",
       "10    Excited to meet the @samsungmobileus at #sxsw ...\n",
       "11    Find &amp; Start Impromptu Parties at #SXSW Wi...\n",
       "12    Foursquare ups the game, just in time for #SXS...\n",
       "13    Gotta love this #SXSW Google Calendar featurin...\n",
       "14    Great #sxsw ipad app from @madebymany: http://...\n",
       "15    haha, awesomely rad iPad app by @madebymany ht...\n",
       "16    Holler Gram for iPad on the iTunes App Store -...\n",
       "17    I just noticed DST is coming this weekend. How...\n",
       "18    Just added my #SXSW flights to @planely. Match...\n",
       "19    Must have #SXSW app! RT @malbonster: Lovely re...\n",
       "20    Need to buy an iPad2 while I'm in Austin at #s...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:25.622045Z",
     "start_time": "2022-05-09T20:43:25.607758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     iphon hrs tweet rise dead need upgrad plugin s...\n",
       "1     know awesom ipad iphon app like appreci design...\n",
       "2                              wait ipad also sale sxsw\n",
       "3           hope year festiv crashi year iphon app sxsw\n",
       "4     great stuff fri sxsw marissa mayer googl tim r...\n",
       "5     new ipad app speechtherapi communic showcas sx...\n",
       "7     sxsw start ctia around corner googleio hop ski...\n",
       "8     beauti smart simpl idea rt wrote hollergram ip...\n",
       "9     count day sxsw plus strong canadian dollar mea...\n",
       "10    excit meet sxsw show sprint galaxi still run a...\n",
       "11    find amp start impromptu parti sxsw http bit l...\n",
       "12    foursquar up game time sxsw http j mp grn stil...\n",
       "13    gotta love sxsw googl calendar featur top part...\n",
       "14                 great sxsw ipad app http tinyurl com\n",
       "15    haha awesom rad ipad app http bit ly htdfim ho...\n",
       "16    holler gram ipad itun app store http co kfn vi...\n",
       "17    notic dst come weekend mani iphon user hour la...\n",
       "18    ad sxsw flight match peopl plane airport also ...\n",
       "19    must sxsw app rt love review forb sxsw ipad ap...\n",
       "20    need buy ipad austin sxsw sure need q austin a...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokens'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:26.398350Z",
     "start_time": "2022-05-09T20:43:25.814755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sxsw', 9108),\n",
       " ('link', 4077),\n",
       " ('rt', 2925),\n",
       " ('ipad', 2848),\n",
       " ('google', 2504),\n",
       " ('apple', 2184),\n",
       " ('quot', 1582),\n",
       " ('iphone', 1497),\n",
       " ('store', 1397),\n",
       " ('new', 1057),\n",
       " ('austin', 919),\n",
       " ('amp', 803),\n",
       " ('app', 791),\n",
       " ('circles', 639),\n",
       " ('social', 632),\n",
       " ('launch', 628),\n",
       " ('today', 566),\n",
       " ('android', 563),\n",
       " ('pop', 543),\n",
       " ('network', 447),\n",
       " ('via', 400),\n",
       " ('line', 391),\n",
       " ('get', 383),\n",
       " ('free', 378),\n",
       " ('called', 353),\n",
       " ('mobile', 342),\n",
       " ('party', 335),\n",
       " ('sxswi', 333),\n",
       " ('major', 301),\n",
       " ('one', 297),\n",
       " ('like', 275),\n",
       " ('w', 260),\n",
       " ('time', 259),\n",
       " ('check', 257),\n",
       " ('temporary', 254),\n",
       " ('opening', 242),\n",
       " ('possibly', 240),\n",
       " ('day', 228),\n",
       " ('people', 223),\n",
       " ('see', 217),\n",
       " ('downtown', 216),\n",
       " ('mayer', 212),\n",
       " ('great', 211),\n",
       " ('going', 211),\n",
       " ('maps', 211),\n",
       " ('apps', 209),\n",
       " ('go', 201),\n",
       " ('popup', 198),\n",
       " ('need', 196),\n",
       " ('open', 193)]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = FreqDist()\n",
    "\n",
    "for tweet in df['text'].map(lambda x: prepare_doc(x, stem = False)):\n",
    "    for word in tweet.split():\n",
    "        word_freq[word] += 1\n",
    "        \n",
    "word_freq.most_common(n = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the total value counts, we can identify some other tokens/words that might be worth adding to our stopwords list:\n",
    "- `sxsw` & `sxswi` / `austin` - tokens that refer to setting - all tweets in corpus seem to be pulled from a South by Southwest (SXSW) festival event.\n",
    "- `rt` / `link` / `quot` / `mobile` - tokens that refer to Twitter interactions or metadata about the post itself; not semanticaly useful information\n",
    "- `amp` - ampersand (&) character that was improperly transcoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:26.616164Z",
     "start_time": "2022-05-09T20:43:26.604016Z"
    }
   },
   "outputs": [],
   "source": [
    "sw.extend([\n",
    "    'sxsw',\n",
    "    'sxswi',\n",
    "    'austin',\n",
    "    'rt',\n",
    "    'quot',\n",
    "    'mention',\n",
    "    'link',\n",
    "    'amp',\n",
    "    'mobil'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:26.846599Z",
     "start_time": "2022-05-09T20:43:26.831948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'No emotion toward brand or product',\n",
       "       'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "df['target'] = le.fit_transform(df['emotion'])\n",
    "\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:27.081493Z",
     "start_time": "2022-05-09T20:43:27.069493Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>product_name</th>\n",
       "      <th>emotion</th>\n",
       "      <th>tokens</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>iphon hrs tweet rise dead need upgrad plugin s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>know awesom ipad iphon app like appreci design...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>wait ipad also sale sxsw</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festiv crashi year iphon app sxsw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>great stuff fri sxsw marissa mayer googl tim r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ipad everywher sxsw link</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>wave buzz rt interrupt regular schedul sxsw ge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>googl zeiger physician never report potenti ae...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>verizon iphon custom complain time fell back h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>rt googl test check offer sxsw link</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8569 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text        product_name  \\\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone   \n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3     @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "...                                                 ...                 ...   \n",
       "8716                      Ipad everywhere. #SXSW {link}                iPad   \n",
       "8717  Wave, buzz... RT @mention We interrupt your re...                 NaN   \n",
       "8718  Google's Zeiger, a physician never reported po...                 NaN   \n",
       "8719  Some Verizon iPhone customers complained their...                 NaN   \n",
       "8720  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...                 NaN   \n",
       "\n",
       "                                 emotion  \\\n",
       "0                       Negative emotion   \n",
       "1                       Positive emotion   \n",
       "2                       Positive emotion   \n",
       "3                       Negative emotion   \n",
       "4                       Positive emotion   \n",
       "...                                  ...   \n",
       "8716                    Positive emotion   \n",
       "8717  No emotion toward brand or product   \n",
       "8718  No emotion toward brand or product   \n",
       "8719  No emotion toward brand or product   \n",
       "8720  No emotion toward brand or product   \n",
       "\n",
       "                                                 tokens  target  \n",
       "0     iphon hrs tweet rise dead need upgrad plugin s...       0  \n",
       "1     know awesom ipad iphon app like appreci design...       2  \n",
       "2                              wait ipad also sale sxsw       2  \n",
       "3           hope year festiv crashi year iphon app sxsw       0  \n",
       "4     great stuff fri sxsw marissa mayer googl tim r...       2  \n",
       "...                                                 ...     ...  \n",
       "8716                           ipad everywher sxsw link       2  \n",
       "8717  wave buzz rt interrupt regular schedul sxsw ge...       1  \n",
       "8718  googl zeiger physician never report potenti ae...       1  \n",
       "8719  verizon iphon custom complain time fell back h...       1  \n",
       "8720                rt googl test check offer sxsw link       1  \n",
       "\n",
       "[8569 rows x 5 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trimming the dataframe display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:27.299061Z",
     "start_time": "2022-05-09T20:43:27.286467Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = df[['text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:27.522582Z",
     "start_time": "2022-05-09T20:43:27.509830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8569 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target\n",
       "0     .@wesley83 I have a 3G iPhone. After 3 hrs twe...       0\n",
       "1     @jessedee Know about @fludapp ? Awesome iPad/i...       2\n",
       "2     @swonderlin Can not wait for #iPad 2 also. The...       2\n",
       "3     @sxsw I hope this year's festival isn't as cra...       0\n",
       "4     @sxtxstate great stuff on Fri #SXSW: Marissa M...       2\n",
       "...                                                 ...     ...\n",
       "8716                      Ipad everywhere. #SXSW {link}       2\n",
       "8717  Wave, buzz... RT @mention We interrupt your re...       1\n",
       "8718  Google's Zeiger, a physician never reported po...       1\n",
       "8719  Some Verizon iPhone customers complained their...       1\n",
       "8720  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...       1\n",
       "\n",
       "[8569 rows x 2 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:27.750255Z",
     "start_time": "2022-05-09T20:43:27.736245Z"
    }
   },
   "outputs": [],
   "source": [
    "X = corpus.text\n",
    "y = corpus.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:27.984552Z",
     "start_time": "2022-05-09T20:43:27.971235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       .@wesley83 I have a 3G iPhone. After 3 hrs twe...\n",
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "3       @sxsw I hope this year's festival isn't as cra...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "                              ...                        \n",
       "8716                        Ipad everywhere. #SXSW {link}\n",
       "8717    Wave, buzz... RT @mention We interrupt your re...\n",
       "8718    Google's Zeiger, a physician never reported po...\n",
       "8719    Some Verizon iPhone customers complained their...\n",
       "8720    �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mentio...\n",
       "Name: text, Length: 8569, dtype: object"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:28.201933Z",
     "start_time": "2022-05-09T20:43:28.188368Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 138)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:35.641000Z",
     "start_time": "2022-05-09T20:43:33.824425Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abba</th>\n",
       "      <th>aber</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abound</th>\n",
       "      <th>...</th>\n",
       "      <th>zlf</th>\n",
       "      <th>zms</th>\n",
       "      <th>zomb</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zynga</th>\n",
       "      <th>zzzs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8637</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8060</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5629</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4030</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6426 rows × 5961 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aapl  aaron  ab  abacus  abba  aber  abil  abl  abnorm  abound  ...  \\\n",
       "8637     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "8060     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "2083     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "2266     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "5629     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "...    ...    ...  ..     ...   ...   ...   ...  ...     ...     ...  ...   \n",
       "5246     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "593      0      0   0       0     0     0     0    0       0       0  ...   \n",
       "6537     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "4030     0      0   0       0     0     0     0    0       0       0  ...   \n",
       "899      0      0   0       0     0     0     0    0       0       0  ...   \n",
       "\n",
       "      zlf  zms  zomb  zombi  zomg  zone  zoom  zuckerberg  zynga  zzzs  \n",
       "8637    0    0     0      0     0     0     0           0      0     0  \n",
       "8060    0    0     0      0     0     0     0           0      0     0  \n",
       "2083    0    0     0      0     0     0     0           0      0     0  \n",
       "2266    0    0     0      0     0     0     0           0      0     0  \n",
       "5629    0    0     0      0     0     0     0           0      0     0  \n",
       "...   ...  ...   ...    ...   ...   ...   ...         ...    ...   ...  \n",
       "5246    0    0     0      0     0     0     0           0      0     0  \n",
       "593     0    0     0      0     0     0     0           0      0     0  \n",
       "6537    0    0     0      0     0     0     0           0      0     0  \n",
       "4030    0    0     0      0     0     0     0           0      0     0  \n",
       "899     0    0     0      0     0     0     0           0      0     0  \n",
       "\n",
       "[6426 rows x 5961 columns]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vec = CountVectorizer(token_pattern = r\"(?<![@A-Za-z0-9_])([a-zA-Z]+(?:'[a-z]+)?)\",\n",
    "                        stop_words = sw,\n",
    "                        preprocessor = prepare_doc)\n",
    "\n",
    "X_tr_vec = c_vec.fit_transform(X_train)\n",
    "\n",
    "X_tr_vec = pd.DataFrame.sparse.from_spmatrix(X_tr_vec)\n",
    "\n",
    "X_tr_vec.columns = sorted(c_vec.vocabulary_)\n",
    "\n",
    "X_tr_vec.set_index(y_train.index,\n",
    "                   inplace = True)\n",
    "\n",
    "X_tr_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T21:24:28.006336Z",
     "start_time": "2022-05-09T21:24:27.989273Z"
    }
   },
   "source": [
    "## Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T20:43:47.079066Z",
     "start_time": "2022-05-09T20:43:36.776206Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.818\n",
      "Test accuracy:     0.647\n",
      "\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.736\n",
      "Test F1 score:     0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   10.2s finished\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "mnb_cv_one = cross_validate(mnb,\n",
    "                            X_tr_vec,\n",
    "                            y_train,\n",
    "                            cv = 5,\n",
    "                            scoring = ('accuracy', 'f1_macro'),\n",
    "                            verbose = 1,\n",
    "                            n_jobs = -2,\n",
    "                            return_train_score = True)\n",
    "\n",
    "cv_printScores(mnb_cv_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Way** overfit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
