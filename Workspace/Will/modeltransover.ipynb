{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set-up of DF and functions, adapted from Saad's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder_path = '../../data/'\n",
    "data_df = pd.read_csv(dataFolder_path+'judge_1377884607_tweet_product_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(treebank_tag):\n",
    "#     '''\n",
    "#     Translate nltk POS to wordnet tags\n",
    "#     '''\n",
    "#     if treebank_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif treebank_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif treebank_tag.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif treebank_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return wordnet.NOUN\n",
    "\n",
    "\n",
    "def doc_preparer(doc, stem = False, stop_words=sw):\n",
    "    '''\n",
    "\n",
    "    :param doc: a document from the satire corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    #Stemming seems to work better. Lemming can't identify plurals of products\n",
    "    \n",
    "    \n",
    "#     lemmed_keywords = ['apple',\n",
    "#                 'ipad', 'ipads',\n",
    "#                 'iphone', 'iphones',\n",
    "#                 'itunes',\n",
    "#                 'google', 'googled',\n",
    "#                 'android', 'droid', 'androids', 'droids',\n",
    "#                 'circle', 'circles'\n",
    "#                 'app', 'apps']\n",
    "\n",
    "#     stemmed_keywords = ['appl',\n",
    "#                         'ipad',\n",
    "#                         'iphon',\n",
    "#                         'itun',\n",
    "#                         'googl',\n",
    "#                         'android',\n",
    "#                         'droid',\n",
    "#                         'circl',\n",
    "#                         'app']\n",
    "\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "#     doc = pos_tag(doc)\n",
    "#     doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "#     doc = [word for word in doc if word in lemmed_keywords]\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_stemmer = nltk.stem.PorterStemmer()\n",
    "    if stem:\n",
    "        doc = [p_stemmer.stem(word) for word in doc if p_stemmer.stem(word)]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "def cv_printScores(cv_metric):\n",
    "    print('CV Results')\n",
    "    print('='*32)\n",
    "    print('Accuracy')\n",
    "    print('-'*32)\n",
    "    print(f\"Training accuracy: {cv_metric['train_accuracy'].mean():.3f}\")\n",
    "    print(f\"Test accuracy:     {cv_metric['test_accuracy'].mean():.3f}\")\n",
    "    print('F-1 Score')\n",
    "    print('-'*32)\n",
    "    print(f\"Training F1 score: {cv_metric['train_f1_macro'].mean():.3f}\")\n",
    "    print(f\"Test F1 score:     {cv_metric['test_f1_macro'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls & I can't tell\n",
    "data_df.dropna(subset=['tweet_text'],inplace=True)\n",
    "data_df = data_df[data_df.is_there_an_emotion_directed_at_a_brand_or_product != \"I can't tell\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend Stop words\n",
    "sw.extend(['sxsw','rt','quot','austin','sxswi','mention','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'No emotion toward brand or product',\n",
       "       'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode targets\n",
    "le = LabelEncoder()\n",
    "data_df['sentiment_target'] = le.fit_transform(data_df.is_there_an_emotion_directed_at_a_brand_or_product)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>sentiment_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    tweet_text  \\\n",
       "0              .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                              @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                           @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4          @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  sentiment_target  \n",
       "0                                   Negative emotion                 0  \n",
       "1                                   Positive emotion                 2  \n",
       "2                                   Positive emotion                 2  \n",
       "3                                   Negative emotion                 0  \n",
       "4                                   Positive emotion                 2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bring in translated DF\n",
    "neg_tran_df = pd.read_csv('neg_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up DF from CSV\n",
    "neg_tran_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "neg_tran_df.set_index('Unnamed: 0.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_neg_df = pd.concat([data_df, neg_tran_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>sentiment_target</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>Google Guy from #SXSW Talk explains how he did realistic Twitter bots as an experiment.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>8603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>I think my Effing husband stands in line for a #ipad 2.Can someone point out the line-up for woman number 2? #Sxswi #sxsw</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>8611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>I am pretty sure that the discussion participant who thinks \"Apple drowned in her success\".</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>8638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Hey, does someone do #SXSW who registers for the GroupMe groups? I got it on my iPhone, but nobody else is there, so ... somehow useless.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>8672.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>According to Diller, Google TV &amp; Quot could be transferred from the PlayStation and the Xbox, which are essentially ready today.&amp; Quot; #sxsw #diller</td>\n",
       "      <td>Other Google product or service</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>0</td>\n",
       "      <td>8709.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9114 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                tweet_text  \\\n",
       "0                          .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1              @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                          @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                       @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                      @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "..                                                                                                                                                     ...   \n",
       "540                                                                Google Guy from #SXSW Talk explains how he did realistic Twitter bots as an experiment.   \n",
       "541                              I think my Effing husband stands in line for a #ipad 2.Can someone point out the line-up for woman number 2? #Sxswi #sxsw   \n",
       "542                                                            I am pretty sure that the discussion participant who thinks \"Apple drowned in her success\".   \n",
       "543              Hey, does someone do #SXSW who registers for the GroupMe groups? I got it on my iPhone, but nobody else is there, so ... somehow useless.   \n",
       "544  According to Diller, Google TV & Quot could be transferred from the PlayStation and the Xbox, which are essentially ready today.& Quot; #sxsw #diller   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "..                               ...   \n",
       "540                              NaN   \n",
       "541                             iPad   \n",
       "542                            Apple   \n",
       "543                              NaN   \n",
       "544  Other Google product or service   \n",
       "\n",
       "    is_there_an_emotion_directed_at_a_brand_or_product  sentiment_target  \\\n",
       "0                                     Negative emotion                 0   \n",
       "1                                     Positive emotion                 2   \n",
       "2                                     Positive emotion                 2   \n",
       "3                                     Negative emotion                 0   \n",
       "4                                     Positive emotion                 2   \n",
       "..                                                 ...               ...   \n",
       "540                                   Negative emotion                 0   \n",
       "541                                   Negative emotion                 0   \n",
       "542                                   Negative emotion                 0   \n",
       "543                                   Negative emotion                 0   \n",
       "544                                   Negative emotion                 0   \n",
       "\n",
       "     Unnamed: 0.1  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "..            ...  \n",
       "540        8603.0  \n",
       "541        8611.0  \n",
       "542        8638.0  \n",
       "543        8672.0  \n",
       "544        8709.0  \n",
       "\n",
       "[9114 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stem'd versions\n",
    "data_df['stemmed_tokens'] = data_df['tweet_text'].map(lambda x:doc_preparer(x,stem=True))\n",
    "over_neg_df['stemmed_tokens'] = over_neg_df['tweet_text'].map(lambda x:doc_preparer(x,stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not sure how to do an apples to apples comparision without data leakage.  Taking a rough look:\n",
    "X = data_df['stemmed_tokens']\n",
    "y = data_df['sentiment_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)\n",
    "\n",
    "X_neg = over_neg_df['stemmed_tokens']\n",
    "y_neg = over_neg_df['sentiment_target']\n",
    "\n",
    "X_neg_train, X_neg_test, y_neg_train, y_neg_test = train_test_split(X_neg, y_neg,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   5 | elapsed:   11.2s remaining:   16.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.996\n",
      "Test accuracy:     0.680\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.997\n",
      "Test F1 score:     0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   12.8s finished\n"
     ]
    }
   ],
   "source": [
    "# Default DF\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = tvec.fit_transform(X_train)\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_train_vec.columns = sorted(tvec.vocabulary_)\n",
    "X_train_vec.set_index(y_train.index, inplace=True)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "tvec_rfc_cvResults = cross_validate(rfc,\n",
    "                                    X_train_vec,\n",
    "                                    y_train,\n",
    "                                    scoring=('accuracy', 'f1_macro'),\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-2,\n",
    "                                    return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_rfc_cvResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   5 | elapsed:   11.6s remaining:   17.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.996\n",
      "Test accuracy:     0.678\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.997\n",
      "Test F1 score:     0.610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   12.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Test with oversampled neg DF. Same params and setup (will be variation from train/test split)\n",
    "\n",
    "tvec_neg = TfidfVectorizer()\n",
    "\n",
    "X_neg_train_vec = tvec_neg.fit_transform(X_neg_train)\n",
    "X_neg_train_vec = pd.DataFrame.sparse.from_spmatrix(X_neg_train_vec)\n",
    "X_neg_train_vec.columns = sorted(tvec_neg.vocabulary_)\n",
    "X_neg_train_vec.set_index(y_neg_train.index, inplace=True)\n",
    "\n",
    "rfc_neg = RandomForestClassifier()\n",
    "\n",
    "tvec_neg_rfc_cvResults = cross_validate(rfc_neg,\n",
    "                                    X_neg_train_vec,\n",
    "                                    y_neg_train,\n",
    "                                    scoring=('accuracy', 'f1_macro'),\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-2,\n",
    "                                    return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_neg_rfc_cvResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfv2",
   "language": "python",
   "name": "tfv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
