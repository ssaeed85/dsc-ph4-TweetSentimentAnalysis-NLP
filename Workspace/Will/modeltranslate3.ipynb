{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set-up of DF and functions, adapted from Saad's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import googletrans\n",
    "import time\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "sw = stopwords.words('english')\n",
    "sw.extend(['sxsw','rt','quot','austin','sxswi','mention','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder_path = '../../data/'\n",
    "data_df = pd.read_csv(dataFolder_path+'judge_1377884607_tweet_product_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_preparer(doc, stem = False, stop_words=sw):\n",
    "    '''\n",
    "\n",
    "    :param doc: a document from the satire corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:â€™[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "#     doc = pos_tag(doc)\n",
    "#     doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "#     doc = [word for word in doc if word in lemmed_keywords]\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_stemmer = nltk.stem.PorterStemmer()\n",
    "    if stem:\n",
    "        doc = [p_stemmer.stem(word) for word in doc if p_stemmer.stem(word)]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "def cv_printScores(cv_metric):\n",
    "    print('CV Results')\n",
    "    print('='*32)\n",
    "    print('Accuracy')\n",
    "    print('-'*32)\n",
    "    print(f\"Training accuracy: {cv_metric['train_accuracy'].mean():.3f}\")\n",
    "    print(f\"Test accuracy:     {cv_metric['test_accuracy'].mean():.3f}\")\n",
    "    print('F-1 Score')\n",
    "    print('-'*32)\n",
    "    print(f\"Training F1 score: {cv_metric['train_f1_macro'].mean():.3f}\")\n",
    "    print(f\"Test F1 score:     {cv_metric['test_f1_macro'].mean():.3f}\")\n",
    "    \n",
    "# Functions from https://github.com/NandhiniN85/Class-Imbalancing/blob/main/NLP%20-%20Class%20Imbalanced.ipynb\n",
    "    \n",
    "def German_translation(x):\n",
    "    # print(x)\n",
    "    time.sleep(1)\n",
    "    german_translation = translator.translate(x, dest='de')\n",
    "    \n",
    "    return german_translation.text\n",
    "\n",
    "def English_translation(x):\n",
    "    # print(x)\n",
    "    time.sleep(1)\n",
    "    english_translation = translator.translate(x, dest='en')\n",
    "    \n",
    "    return english_translation.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls & I can't tell\n",
    "data_df.dropna(subset=['tweet_text'],inplace=True)\n",
    "data_df = data_df[data_df.is_there_an_emotion_directed_at_a_brand_or_product != \"I can't tell\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'No emotion toward brand or product',\n",
       "       'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode targets\n",
    "le = LabelEncoder()\n",
    "data_df['sentiment_target'] = le.fit_transform(data_df.is_there_an_emotion_directed_at_a_brand_or_product)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Three: Pipeline to avoid data leakage in crossval step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nopto\\Anaconda3\\envs\\tfv2\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Including sentinment target with X_train for use in backtranslation of negatives\n",
    "X = data_df[['tweet_text', 'sentiment_target']]\n",
    "y = data_df['sentiment_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state=42)\n",
    "\n",
    "# Remove extraneaous column from X_test\n",
    "X_test.drop('sentiment_target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_translation(df):\n",
    "    temp = df\n",
    "    \n",
    "    temp.tweet_text = temp.tweet_text.apply(lambda x: German_translation(x))\n",
    "    temp.tweet_text = temp.tweet_text.apply(lambda x: English_translation(x))\n",
    "    \n",
    "    return temp\n",
    "\n",
    "def back_trans_neg(Xtrain):\n",
    "    # Check index of X_train against index of back translation to see which negatives are in it, \n",
    "    Xfromcsv = pd.read_csv('backs_trans_fulltrain.csv')\n",
    "    Xfromcsv.set_index('Unnamed: 0', inplace=True)\n",
    "    \n",
    "    backtransdf = Xtrain.loc[Xfromcsv.index]   \n",
    "\n",
    "    # Append the backtranslated versions of the neg in X_train to X_train\n",
    "    X_train_back = pd.concat([Xtrain, backtransdf])\n",
    "    X_train_back.drop('sentiment_target', axis=1, inplace=True)\n",
    "    # Use # of backtranslations added (len), Add that many 0s to y_train  \n",
    "        \n",
    "    return X_train_back\n",
    "\n",
    "def stemmatic(Xtrain):\n",
    "    X_train_stem = Xtrain\n",
    "    X_train_stem['stemmed_tokens'] = X_train_stem['tweet_text'].map(lambda x:doc_preparer(x,stem=True))\n",
    "    X_train_stem.drop('tweet_text', axis=1, inplace=True)\n",
    "    \n",
    "    return X_train_stem    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Save list of Back Translated Negative Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DF of negatives, post train/test split\n",
    "neg_df = X_train.copy()\n",
    "neg_df = neg_df[neg_df.sentiment_target == 0]\n",
    "neg_df = neg_df.drop('sentiment_target', axis=1)\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "neg_X = back_translation(neg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>Hey @mmention was invited to a new group at #SXSW and your Android app crashes again and again when I try to join! WTF? #Sxswfail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>Totalitarian thinking in action: People worldwide come to Austin, TX for #SXSW and decide to spend their time in an Apple store.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>@MENTION, just to talk about mistakes at #SXSW, create the #Netflix #iPhone app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276</th>\n",
       "      <td>RT @MENTION RT @mtion Apple is \"The classic, fascist company in America, &amp; quot; says @mention #SXSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>Rt @mmention &amp; quot;@MENTION - #Aplle is the classic fascist company in America. Really elegant.&amp; Quot; #sxsw #rji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>Lunch with @mmention at #cnngrill. View from the HTML5 developer trenches: Android is painful, iOS is slim (for what @mmention does) #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>New iPhone car correction has already tried to \"change colleagues\". &amp; Quot; vissigots. &amp; Quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>@MENTION Google Circles will be lame.#sxsw &amp; lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Visitor @MENTION IPAD Design Headache #SXSW {Link}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>#SXSW tried for 2 days with iPad with MacBook Pro.Das experiment is over. I love a real keyboard.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                      tweet_text\n",
       "3589           Hey @mmention was invited to a new group at #SXSW and your Android app crashes again and again when I try to join! WTF? #Sxswfail\n",
       "3413            Totalitarian thinking in action: People worldwide come to Austin, TX for #SXSW and decide to spend their time in an Apple store.\n",
       "1788                                                             @MENTION, just to talk about mistakes at #SXSW, create the #Netflix #iPhone app\n",
       "6276                                        RT @MENTION RT @mtion Apple is \"The classic, fascist company in America, & quot; says @mention #SXSW\n",
       "4933                          Rt @mmention & quot;@MENTION - #Aplle is the classic fascist company in America. Really elegant.& Quot; #sxsw #rji\n",
       "...                                                                                                                                          ...\n",
       "3218  Lunch with @mmention at #cnngrill. View from the HTML5 developer trenches: Android is painful, iOS is slim (for what @mmention does) #sxsw\n",
       "2501                                              New iPhone car correction has already tried to \"change colleagues\". & Quot; vissigots. & Quot;\n",
       "3163                                                                                           @MENTION Google Circles will be lame.#sxsw & lt;3\n",
       "65                                                                                           Visitor @MENTION IPAD Design Headache #SXSW {Link}}\n",
       "7397                                           #SXSW tried for 2 days with iPad with MacBook Pro.Das experiment is over. I love a real keyboard.\n",
       "\n",
       "[360 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_X.to_csv(r'backs_trans_fulltrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfromcsv = pd.read_csv('backs_trans_fulltrain.csv')\n",
    "Xfromcsv.set_index('Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>Tech Check podcast -- #SxSW #Android passes #BlackBerry, a big Twitter #fail! -- {link} by @mention #sxsw #cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>In honor of Apple's #SXSW pop-up shop, here are some thoughts on how landlords &amp;amp; leasing agents can utilize pop-up shops. {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>RT @mention Hoot! New Blog post: HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>RT @mention @mention 3 iPhone Apps We'll Be Using at South By Southwest Interactive {link} #SXSW #SXSWi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>#sxsw: @mention intrvw @mention &amp;quot;Schmidt [Google CEO] told me: u'r good at telling stories; go talk to lots of ppl, tell us what u hear&amp;quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>Lunch with @mention at #CNNGrill. View from the HTML5 dev trenches: Android is painful, iOS is sleek (for what @mention is doing) #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>New Iphone autocorrect already tried to change &amp;quot;coworkers&amp;quot; to &amp;quot;visigoths.&amp;quot; Its going to be a long five days of #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>@mention Google Circles will be Lame. #sxsw &amp;lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>attending @mention iPad design headaches #sxsw {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>#sxsw   Tried 2 days with iPAD, w/o MacBook Pro.  the experiment is over. I heart a real keyboard.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6358 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              tweet_text\n",
       "3791                                      Tech Check podcast -- #SxSW #Android passes #BlackBerry, a big Twitter #fail! -- {link} by @mention #sxsw #cnn\n",
       "4683                In honor of Apple's #SXSW pop-up shop, here are some thoughts on how landlords &amp; leasing agents can utilize pop-up shops. {link}\n",
       "5800                                   RT @mention Hoot! New Blog post: HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android {link}\n",
       "4879                                             RT @mention @mention 3 iPhone Apps We'll Be Using at South By Southwest Interactive {link} #SXSW #SXSWi\n",
       "2804  #sxsw: @mention intrvw @mention &quot;Schmidt [Google CEO] told me: u'r good at telling stories; go talk to lots of ppl, tell us what u hear&quot;\n",
       "...                                                                                                                                                  ...\n",
       "3218             Lunch with @mention at #CNNGrill. View from the HTML5 dev trenches: Android is painful, iOS is sleek (for what @mention is doing) #sxsw\n",
       "2501            New Iphone autocorrect already tried to change &quot;coworkers&quot; to &quot;visigoths.&quot; Its going to be a long five days of #sxsw\n",
       "3163                                                                                                   @mention Google Circles will be Lame. #sxsw &lt;3\n",
       "65                                                                                                 attending @mention iPad design headaches #sxsw {link}\n",
       "7397                                                  #sxsw   Tried 2 days with iPAD, w/o MacBook Pro.  the experiment is over. I heart a real keyboard.\n",
       "\n",
       "[6358 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = back_trans_neg(X_train)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "trans_func = FunctionTransformer(back_trans_neg)\n",
    "stem_func = FunctionTransformer(stemmatic)\n",
    "\n",
    "translator = Translator()\n",
    "\n",
    "T_pipe = Pipeline(steps = [\n",
    "                        ('tf', trans_func),\n",
    "                        ('stem', stem_func),\n",
    "                        ('rfc', RandomForestClassifier(random_state=42))\n",
    "                        ])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=42)\n",
    "    \n",
    "param_grid = {'rfc__max_depth':[10, 100]}\n",
    "grid_search = GridSearchCV(estimator=T_pipe,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "cv_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfv2",
   "language": "python",
   "name": "tfv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
