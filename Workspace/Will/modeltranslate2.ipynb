{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Set-up of DF and functions, adapted from Saad's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import googletrans\n",
    "import time\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words\n",
    "sw = stopwords.words('english')\n",
    "sw.extend(['sxsw','rt','quot','austin','sxswi','mention','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder_path = '../../data/'\n",
    "data_df = pd.read_csv(dataFolder_path+'judge_1377884607_tweet_product_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(treebank_tag):\n",
    "#     '''\n",
    "#     Translate nltk POS to wordnet tags\n",
    "#     '''\n",
    "#     if treebank_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif treebank_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif treebank_tag.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif treebank_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return wordnet.NOUN\n",
    "\n",
    "\n",
    "def doc_preparer(doc, stem = False, stop_words=sw):\n",
    "    '''\n",
    "\n",
    "    :param doc: a document from the satire corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    #Stemming seems to work better. Lemming can't identify plurals of products\n",
    "    \n",
    "    \n",
    "#     lemmed_keywords = ['apple',\n",
    "#                 'ipad', 'ipads',\n",
    "#                 'iphone', 'iphones',\n",
    "#                 'itunes',\n",
    "#                 'google', 'googled',\n",
    "#                 'android', 'droid', 'androids', 'droids',\n",
    "#                 'circle', 'circles'\n",
    "#                 'app', 'apps']\n",
    "\n",
    "#     stemmed_keywords = ['appl',\n",
    "#                         'ipad',\n",
    "#                         'iphon',\n",
    "#                         'itun',\n",
    "#                         'googl',\n",
    "#                         'android',\n",
    "#                         'droid',\n",
    "#                         'circl',\n",
    "#                         'app']\n",
    "\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "#     doc = pos_tag(doc)\n",
    "#     doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "#     doc = [word for word in doc if word in lemmed_keywords]\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_stemmer = nltk.stem.PorterStemmer()\n",
    "    if stem:\n",
    "        doc = [p_stemmer.stem(word) for word in doc if p_stemmer.stem(word)]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "def cv_printScores(cv_metric):\n",
    "    print('CV Results')\n",
    "    print('='*32)\n",
    "    print('Accuracy')\n",
    "    print('-'*32)\n",
    "    print(f\"Training accuracy: {cv_metric['train_accuracy'].mean():.3f}\")\n",
    "    print(f\"Test accuracy:     {cv_metric['test_accuracy'].mean():.3f}\")\n",
    "    print('F-1 Score')\n",
    "    print('-'*32)\n",
    "    print(f\"Training F1 score: {cv_metric['train_f1_macro'].mean():.3f}\")\n",
    "    print(f\"Test F1 score:     {cv_metric['test_f1_macro'].mean():.3f}\")\n",
    "    \n",
    "# Functions from https://github.com/NandhiniN85/Class-Imbalancing/blob/main/NLP%20-%20Class%20Imbalanced.ipynb\n",
    "    \n",
    "def German_translation(x):\n",
    "    # print(x)    \n",
    "    german_translation = translator.translate(x, dest='de')    \n",
    "    return german_translation.text\n",
    "\n",
    "def English_translation(x):\n",
    "    # print(x)    \n",
    "    english_translation = translator.translate(x, dest='en')\n",
    "    #time.sleep(1)\n",
    "    return english_translation.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Nulls & I can't tell\n",
    "data_df.dropna(subset=['tweet_text'],inplace=True)\n",
    "data_df = data_df[data_df.is_there_an_emotion_directed_at_a_brand_or_product != \"I can't tell\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'No emotion toward brand or product',\n",
       "       'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode targets\n",
    "le = LabelEncoder()\n",
    "data_df['sentiment_target'] = le.fit_transform(data_df.is_there_an_emotion_directed_at_a_brand_or_product)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split before stemming for purposes of translation\n",
    "X = data_df['tweet_text']\n",
    "y = data_df['sentiment_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of negatives from training data\n",
    "X_train_df = X_train.to_frame()\n",
    "neg_df = X_train_df.copy()\n",
    "neg_df['sentiment_target'] = y_train\n",
    "neg_df = neg_df[neg_df.sentiment_target == 0]\n",
    "\n",
    "neg_X = neg_df.drop('sentiment_target', axis=1)\n",
    "neg_y = neg_df.sentiment_target\n",
    "\n",
    "y_train_over = pd.concat([y_train, neg_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5998 entries, 3791 to 7397\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_text  5998 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 93.7+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate to negative tweet text in train to German\n",
    "translator = Translator()\n",
    "\n",
    "neg_X.tweet_text = neg_X.tweet_text.apply(lambda x: German_translation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output\n",
    "# neg_X.tweet_text.to_csv(r'neg_de_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate back into English\n",
    "neg_X.tweet_text = neg_X.tweet_text.apply(lambda x: English_translation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output for easier reuse\n",
    "# neg_X.tweet_text.to_csv(r'negtrain2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>Tech Check podcast -- #SxSW #Android passes #BlackBerry, a big Twitter #fail! -- {link} by @mention #sxsw #cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>In honor of Apple's #SXSW pop-up shop, here are some thoughts on how landlords &amp;amp; leasing agents can utilize pop-up shops. {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>RT @mention Hoot! New Blog post: HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android {link}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>RT @mention @mention 3 iPhone Apps We'll Be Using at South By Southwest Interactive {link} #SXSW #SXSWi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>#sxsw: @mention intrvw @mention &amp;quot;Schmidt [Google CEO] told me: u'r good at telling stories; go talk to lots of ppl, tell us what u hear&amp;quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>Lunch with @mmention at #cnngrill. View from the HTML5 developer trenches: Android is painful, iOS is slim (for what @mmention does) #sxsw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>New iPhone car correction has already tried to \"change colleagues\". &amp; Quot; vissigots. &amp; Quot;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>@MENTION Google Circles will be lame.#sxsw &amp; lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Visitor @MENTION IPAD Design Headache #SXSW {Link}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>#SXSW tried for 2 days with iPad with MacBook Pro.Das experiment is over. I love a real keyboard.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6358 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              tweet_text\n",
       "3791                                      Tech Check podcast -- #SxSW #Android passes #BlackBerry, a big Twitter #fail! -- {link} by @mention #sxsw #cnn\n",
       "4683                In honor of Apple's #SXSW pop-up shop, here are some thoughts on how landlords &amp; leasing agents can utilize pop-up shops. {link}\n",
       "5800                                   RT @mention Hoot! New Blog post: HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android {link}\n",
       "4879                                             RT @mention @mention 3 iPhone Apps We'll Be Using at South By Southwest Interactive {link} #SXSW #SXSWi\n",
       "2804  #sxsw: @mention intrvw @mention &quot;Schmidt [Google CEO] told me: u'r good at telling stories; go talk to lots of ppl, tell us what u hear&quot;\n",
       "...                                                                                                                                                  ...\n",
       "3218          Lunch with @mmention at #cnngrill. View from the HTML5 developer trenches: Android is painful, iOS is slim (for what @mmention does) #sxsw\n",
       "2501                                                      New iPhone car correction has already tried to \"change colleagues\". & Quot; vissigots. & Quot;\n",
       "3163                                                                                                   @MENTION Google Circles will be lame.#sxsw & lt;3\n",
       "65                                                                                                   Visitor @MENTION IPAD Design Headache #SXSW {Link}}\n",
       "7397                                                   #SXSW tried for 2 days with iPad with MacBook Pro.Das experiment is over. I love a real keyboard.\n",
       "\n",
       "[6358 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add oversample X to X_train\n",
    "X_train_over = pd.concat([X_train_df, neg_X])\n",
    "X_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6358 entries, 3791 to 7397\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   tweet_text  6358 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 99.3+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_over.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stem'd versions\n",
    "#X_train_over.reset_index(inplace=True)\n",
    "X_train_over['stemmed_tokens'] = X_train_over['tweet_text'].map(lambda x:doc_preparer(x,stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# RFC with data_df\n",
    "X = data_df['stemmed_tokens']\n",
    "y = data_df['sentiment_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   5 | elapsed:   13.2s remaining:   19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.997\n",
      "Test accuracy:     0.670\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.997\n",
      "Test F1 score:     0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   15.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Default DF\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = tvec.fit_transform(X_train)\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_train_vec.columns = sorted(tvec.vocabulary_)\n",
    "X_train_vec.set_index(y_train.index, inplace=True)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "tvec_rfc_cvResults = cross_validate(rfc,\n",
    "                                    X_train_vec,\n",
    "                                    y_train,\n",
    "                                    scoring=('accuracy', 'f1_macro'),\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-2,\n",
    "                                    return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_rfc_cvResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with oversampled neg DF. Same params and setup (will be variation from train/test split)\n",
    "'''X_neg = over_neg_df['stemmed_tokens']\n",
    "y_neg = over_neg_df['sentiment_target']\n",
    "\n",
    "X_neg_train, X_neg_test, y_neg_train, y_neg_test = train_test_split(X_neg, y_neg,test_size = 0.3)\n",
    "\n",
    "tvec_neg = TfidfVectorizer()\n",
    "\n",
    "X_neg_train_vec = tvec_neg.fit_transform(X_neg_train)\n",
    "X_neg_train_vec = pd.DataFrame.sparse.from_spmatrix(X_neg_train_vec)\n",
    "X_neg_train_vec.columns = sorted(tvec_neg.vocabulary_)\n",
    "X_neg_train_vec.set_index(y_neg_train.index, inplace=True)\n",
    "\n",
    "rfc_neg = RandomForestClassifier()\n",
    "\n",
    "tvec_neg_rfc_cvResults = cross_validate(rfc_neg,\n",
    "                                    X_neg_train_vec,\n",
    "                                    y_neg_train,\n",
    "                                    scoring=('accuracy', 'f1_macro'),\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-2,\n",
    "                                    return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_neg_rfc_cvResults)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>Tech Check podcast -- #SxSW #Android passes #BlackBerry, a big Twitter #fail! -- {link} by @mention #sxsw #cnn</td>\n",
       "      <td>tech check podcast android pass blackberri big twitter fail cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>In honor of Apple's #SXSW pop-up shop, here are some thoughts on how landlords &amp;amp; leasing agents can utilize pop-up shops. {link}</td>\n",
       "      <td>honor appl pop shop thought landlord amp leas agent util pop shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>RT @mention Hoot! New Blog post: HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp;amp; Android {link}</td>\n",
       "      <td>hoot new blog post hootsuit mobil updat iphon blackberri amp android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>RT @mention @mention 3 iPhone Apps We'll Be Using at South By Southwest Interactive {link} #SXSW #SXSWi</td>\n",
       "      <td>iphon app use south southwest interact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>#sxsw: @mention intrvw @mention &amp;quot;Schmidt [Google CEO] told me: u'r good at telling stories; go talk to lots of ppl, tell us what u hear&amp;quot;</td>\n",
       "      <td>intrvw schmidt googl ceo told u r good tell stori go talk lot ppl tell us u hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>Lunch with @mmention at #cnngrill. View from the HTML5 developer trenches: Android is painful, iOS is slim (for what @mmention does) #sxsw</td>\n",
       "      <td>lunch mmention cnngrill view html develop trench android pain io slim mmention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>New iPhone car correction has already tried to \"change colleagues\". &amp; Quot; vissigots. &amp; Quot;</td>\n",
       "      <td>new iphon car correct alreadi tri chang colleagu vissigot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>@MENTION Google Circles will be lame.#sxsw &amp; lt;3</td>\n",
       "      <td>googl circl lame lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Visitor @MENTION IPAD Design Headache #SXSW {Link}}</td>\n",
       "      <td>visitor ipad design headach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>#SXSW tried for 2 days with iPad with MacBook Pro.Das experiment is over. I love a real keyboard.</td>\n",
       "      <td>tri day ipad macbook pro da experi love real keyboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6358 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                              tweet_text  \\\n",
       "3791                                      Tech Check podcast -- #SxSW #Android passes #BlackBerry, a big Twitter #fail! -- {link} by @mention #sxsw #cnn   \n",
       "4683                In honor of Apple's #SXSW pop-up shop, here are some thoughts on how landlords &amp; leasing agents can utilize pop-up shops. {link}   \n",
       "5800                                   RT @mention Hoot! New Blog post: HootSuite Mobile for #SXSW ~ Updates for iPhone, BlackBerry &amp; Android {link}   \n",
       "4879                                             RT @mention @mention 3 iPhone Apps We'll Be Using at South By Southwest Interactive {link} #SXSW #SXSWi   \n",
       "2804  #sxsw: @mention intrvw @mention &quot;Schmidt [Google CEO] told me: u'r good at telling stories; go talk to lots of ppl, tell us what u hear&quot;   \n",
       "...                                                                                                                                                  ...   \n",
       "3218          Lunch with @mmention at #cnngrill. View from the HTML5 developer trenches: Android is painful, iOS is slim (for what @mmention does) #sxsw   \n",
       "2501                                                      New iPhone car correction has already tried to \"change colleagues\". & Quot; vissigots. & Quot;   \n",
       "3163                                                                                                   @MENTION Google Circles will be lame.#sxsw & lt;3   \n",
       "65                                                                                                   Visitor @MENTION IPAD Design Headache #SXSW {Link}}   \n",
       "7397                                                   #SXSW tried for 2 days with iPad with MacBook Pro.Das experiment is over. I love a real keyboard.   \n",
       "\n",
       "                                                                        stemmed_tokens  \n",
       "3791                   tech check podcast android pass blackberri big twitter fail cnn  \n",
       "4683                 honor appl pop shop thought landlord amp leas agent util pop shop  \n",
       "5800              hoot new blog post hootsuit mobil updat iphon blackberri amp android  \n",
       "4879                                            iphon app use south southwest interact  \n",
       "2804  intrvw schmidt googl ceo told u r good tell stori go talk lot ppl tell us u hear  \n",
       "...                                                                                ...  \n",
       "3218    lunch mmention cnngrill view html develop trench android pain io slim mmention  \n",
       "2501                         new iphon car correct alreadi tri chang colleagu vissigot  \n",
       "3163                                                               googl circl lame lt  \n",
       "65                                                         visitor ipad design headach  \n",
       "7397                             tri day ipad macbook pro da experi love real keyboard  \n",
       "\n",
       "[6358 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over.drop('tweet_text', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech check podcast android pass blackberri big twitter fail cnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>honor appl pop shop thought landlord amp leas agent util pop shop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hoot new blog post hootsuit mobil updat iphon blackberri amp android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphon app use south southwest interact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intrvw schmidt googl ceo told u r good tell stori go talk lot ppl tell us u hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>lunch mmention cnngrill view html develop trench android pain io slim mmention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>new iphon car correct alreadi tri chang colleagu vissigot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6355</th>\n",
       "      <td>googl circl lame lt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>visitor ipad design headach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6357</th>\n",
       "      <td>tri day ipad macbook pro da experi love real keyboard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6358 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        stemmed_tokens\n",
       "0                      tech check podcast android pass blackberri big twitter fail cnn\n",
       "1                    honor appl pop shop thought landlord amp leas agent util pop shop\n",
       "2                 hoot new blog post hootsuit mobil updat iphon blackberri amp android\n",
       "3                                               iphon app use south southwest interact\n",
       "4     intrvw schmidt googl ceo told u r good tell stori go talk lot ppl tell us u hear\n",
       "...                                                                                ...\n",
       "6353    lunch mmention cnngrill view html develop trench android pain io slim mmention\n",
       "6354                         new iphon car correct alreadi tri chang colleagu vissigot\n",
       "6355                                                               googl circl lame lt\n",
       "6356                                                       visitor ipad design headach\n",
       "6357                             tri day ipad macbook pro da experi love real keyboard\n",
       "\n",
       "[6358 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_over.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done   2 out of   5 | elapsed:   13.9s remaining:   20.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.970\n",
      "Test accuracy:     0.690\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.972\n",
      "Test F1 score:     0.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   15.7s finished\n"
     ]
    }
   ],
   "source": [
    "tvec_neg = TfidfVectorizer()\n",
    "\n",
    "X_neg_train_vec = tvec_neg.fit_transform(X_train_over.stemmed_tokens)\n",
    "X_neg_train_vec = pd.DataFrame.sparse.from_spmatrix(X_neg_train_vec)\n",
    "X_neg_train_vec.columns = sorted(tvec_neg.vocabulary_)\n",
    "X_neg_train_vec.set_index(y_train_over.index, inplace=True)\n",
    "\n",
    "rfc_neg = RandomForestClassifier()\n",
    "\n",
    "tvec_neg_rfc_cvResults = cross_validate(rfc_neg,\n",
    "                                    X_neg_train_vec,\n",
    "                                    y_train_over,\n",
    "                                    scoring=('accuracy', 'f1_macro'),\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-2,\n",
    "                                    return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_neg_rfc_cvResults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfv2",
   "language": "python",
   "name": "tfv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
