{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695e7cdc",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91258ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0fb176",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.560322Z",
     "start_time": "2022-05-09T05:46:33.276554Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 280\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "# import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf1b269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.576332Z",
     "start_time": "2022-05-09T05:46:34.561322Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append( '../../src' )\n",
    "from pandas_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73058b5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.590893Z",
     "start_time": "2022-05-09T05:46:34.578338Z"
    }
   },
   "outputs": [],
   "source": [
    "dataFolder_path = '../../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7876da2",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a02fd7c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:56:07.166414Z",
     "start_time": "2022-05-09T05:56:07.146409Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_wordnet_pos(treebank_tag):\n",
    "#     '''\n",
    "#     Translate nltk POS to wordnet tags\n",
    "#     '''\n",
    "#     if treebank_tag.startswith('J'):\n",
    "#         return wordnet.ADJ\n",
    "#     elif treebank_tag.startswith('V'):\n",
    "#         return wordnet.VERB\n",
    "#     elif treebank_tag.startswith('N'):\n",
    "#         return wordnet.NOUN\n",
    "#     elif treebank_tag.startswith('R'):\n",
    "#         return wordnet.ADV\n",
    "#     else:\n",
    "#         return wordnet.NOUN\n",
    "\n",
    "\n",
    "def doc_preparer(doc, stem = False, stop_words=sw):\n",
    "    '''\n",
    "\n",
    "    :param doc: a document from the satire corpus \n",
    "    :return: a document string with words which have been \n",
    "            lemmatized, \n",
    "            parsed for stopwords, \n",
    "            made lowercase,\n",
    "            and stripped of punctuation and numbers.\n",
    "    '''\n",
    "    #Stemming seems to work better. Lemming can't identify plurals of products\n",
    "    \n",
    "    \n",
    "#     lemmed_keywords = ['apple',\n",
    "#                 'ipad', 'ipads',\n",
    "#                 'iphone', 'iphones',\n",
    "#                 'itunes',\n",
    "#                 'google', 'googled',\n",
    "#                 'android', 'droid', 'androids', 'droids',\n",
    "#                 'circle', 'circles'\n",
    "#                 'app', 'apps']\n",
    "\n",
    "#     stemmed_keywords = ['appl',\n",
    "#                         'ipad',\n",
    "#                         'iphon',\n",
    "#                         'itun',\n",
    "#                         'googl',\n",
    "#                         'android',\n",
    "#                         'droid',\n",
    "#                         'circl',\n",
    "#                         'app']\n",
    "\n",
    "    regex_token = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    doc = regex_token.tokenize(doc)\n",
    "    doc = [word.lower() for word in doc]\n",
    "    doc = [word for word in doc if word not in sw]\n",
    "#     doc = pos_tag(doc)\n",
    "#     doc = [(word[0], get_wordnet_pos(word[1])) for word in doc]\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     doc = [lemmatizer.lemmatize(word[0], word[1]) for word in doc]\n",
    "#     doc = [word for word in doc if word in lemmed_keywords]\n",
    "    \n",
    "    \n",
    "    \n",
    "    p_stemmer = nltk.stem.PorterStemmer()\n",
    "    if stem:\n",
    "        doc = [p_stemmer.stem(word) for word in doc if p_stemmer.stem(word)]\n",
    "    return ' '.join(doc)\n",
    "\n",
    "def cv_printScores(cv_metric):\n",
    "    print('CV Results')\n",
    "    print('='*32)\n",
    "    print('Accuracy')\n",
    "    print('-'*32)\n",
    "    print(f\"Training accuracy: {cv_metric['train_accuracy'].mean():.3f}\")\n",
    "    print(f\"Test accuracy:     {cv_metric['test_accuracy'].mean():.3f}\")\n",
    "    print('F-1 Score')\n",
    "    print('-'*32)\n",
    "    print(f\"Training F1 score: {cv_metric['train_f1_macro'].mean():.3f}\")\n",
    "    print(f\"Test F1 score:     {cv_metric['test_f1_macro'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601621e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.638916Z",
     "start_time": "2022-05-09T05:46:34.607901Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(dataFolder_path+'judge_1377884607_tweet_product_company.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b29a914f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.700537Z",
     "start_time": "2022-05-09T05:46:34.639916Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datframe has 8721 rows and 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Info Table:</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Zeroes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Nulls</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Uniques</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Missing/Unknown</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Details:</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columns:</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet_text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01 %</td>\n",
       "      <td>8694</td>\n",
       "      <td>99.69 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>5552</td>\n",
       "      <td>63.66 %</td>\n",
       "      <td>10</td>\n",
       "      <td>0.11 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Info Table:                                        Zeroes          Nulls  \\\n",
       "Details:                                            Count Fraction Count   \n",
       "Columns:                                                                   \n",
       "tweet_text                                              0   0.00 %     1   \n",
       "emotion_in_tweet_is_directed_at                         0   0.00 %  5552   \n",
       "is_there_an_emotion_directed_at_a_brand_or_product      0   0.00 %     0   \n",
       "\n",
       "Info Table:                                                 Uniques           \\\n",
       "Details:                                           Fraction   Count Fraction   \n",
       "Columns:                                                                       \n",
       "tweet_text                                           0.01 %    8694  99.69 %   \n",
       "emotion_in_tweet_is_directed_at                     63.66 %      10   0.11 %   \n",
       "is_there_an_emotion_directed_at_a_brand_or_product   0.00 %       4   0.05 %   \n",
       "\n",
       "Info Table:                                        Missing/Unknown           \\\n",
       "Details:                                                     Count Fraction   \n",
       "Columns:                                                                      \n",
       "tweet_text                                                       0   0.00 %   \n",
       "emotion_in_tweet_is_directed_at                                  0   0.00 %   \n",
       "is_there_an_emotion_directed_at_a_brand_or_product               0   0.00 %   \n",
       "\n",
       "Info Table:                                        Mean Median  \n",
       "Details:                                                        \n",
       "Columns:                                                        \n",
       "tweet_text                                          0.0    0.0  \n",
       "emotion_in_tweet_is_directed_at                     0.0    0.0  \n",
       "is_there_an_emotion_directed_at_a_brand_or_product  0.0    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataFrame_info(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8b8eb3",
   "metadata": {},
   "source": [
    "Looking at the 1 null in tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f05431b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.716541Z",
     "start_time": "2022-05-09T05:46:34.701538Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_text emotion_in_tweet_is_directed_at  \\\n",
       "6        NaN                             NaN   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "6                 No emotion toward brand or product  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[data_df.tweet_text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24ca7a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.732545Z",
     "start_time": "2022-05-09T05:46:34.717541Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df.dropna(subset=['tweet_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675d5b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:34.748549Z",
     "start_time": "2022-05-09T05:46:34.734545Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8720, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ab20409",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:36.215980Z",
     "start_time": "2022-05-09T05:46:34.749548Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datframe has 8720 rows and 3 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Info Table:</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Zeroes</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Nulls</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Uniques</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Missing/Unknown</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Details:</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th>Count</th>\n",
       "      <th>Fraction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columns:</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tweet_text</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>8693</td>\n",
       "      <td>99.69 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>5551</td>\n",
       "      <td>63.66 %</td>\n",
       "      <td>10</td>\n",
       "      <td>0.11 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05 %</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00 %</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Info Table:                                        Zeroes          Nulls  \\\n",
       "Details:                                            Count Fraction Count   \n",
       "Columns:                                                                   \n",
       "tweet_text                                              0   0.00 %     0   \n",
       "emotion_in_tweet_is_directed_at                         0   0.00 %  5551   \n",
       "is_there_an_emotion_directed_at_a_brand_or_product      0   0.00 %     0   \n",
       "\n",
       "Info Table:                                                 Uniques           \\\n",
       "Details:                                           Fraction   Count Fraction   \n",
       "Columns:                                                                       \n",
       "tweet_text                                           0.00 %    8693  99.69 %   \n",
       "emotion_in_tweet_is_directed_at                     63.66 %      10   0.11 %   \n",
       "is_there_an_emotion_directed_at_a_brand_or_product   0.00 %       4   0.05 %   \n",
       "\n",
       "Info Table:                                        Missing/Unknown           \\\n",
       "Details:                                                     Count Fraction   \n",
       "Columns:                                                                      \n",
       "tweet_text                                                       0   0.00 %   \n",
       "emotion_in_tweet_is_directed_at                                  0   0.00 %   \n",
       "is_there_an_emotion_directed_at_a_brand_or_product               0   0.00 %   \n",
       "\n",
       "Info Table:                                        Mean Median  \n",
       "Details:                                                        \n",
       "Columns:                                                        \n",
       "tweet_text                                          0.0    0.0  \n",
       "emotion_in_tweet_is_directed_at                     0.0    0.0  \n",
       "is_there_an_emotion_directed_at_a_brand_or_product  0.0    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataFrame_info(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d67f45",
   "metadata": {},
   "source": [
    "Lets look at the emotion quotient column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591fca67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:36.231702Z",
     "start_time": "2022-05-09T05:46:36.216982Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    0.591170\n",
       "Positive emotion                      0.329014\n",
       "Negative emotion                      0.062500\n",
       "I can't tell                          0.017317\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.is_there_an_emotion_directed_at_a_brand_or_product.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c4048",
   "metadata": {},
   "source": [
    "Major class imbalance. Should consider dropping \"I can't tell\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efa191cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:36.247033Z",
     "start_time": "2022-05-09T05:46:36.233703Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data_df[data_df.is_there_an_emotion_directed_at_a_brand_or_product == \"I can't tell\" ]\n",
    "\n",
    "data_df = data_df[data_df.is_there_an_emotion_directed_at_a_brand_or_product != \"I can't tell\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdbe87a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:36.263042Z",
     "start_time": "2022-05-09T05:46:36.248046Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8569, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3da51e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T02:36:50.450837Z",
     "start_time": "2022-05-09T02:36:50.432834Z"
    }
   },
   "source": [
    "Lets look at some of the most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fc43408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:36.590857Z",
     "start_time": "2022-05-09T05:46:36.265043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sxsw', 9116),\n",
       " ('mention', 6851),\n",
       " ('link', 4077),\n",
       " ('rt', 2925),\n",
       " ('ipad', 2848),\n",
       " ('google', 2504),\n",
       " ('apple', 2184),\n",
       " ('quot', 1582),\n",
       " ('iphone', 1497),\n",
       " ('store', 1399),\n",
       " ('new', 1057),\n",
       " ('austin', 921),\n",
       " ('amp', 803),\n",
       " ('app', 792),\n",
       " ('circles', 639),\n",
       " ('social', 633),\n",
       " ('launch', 628),\n",
       " ('today', 566),\n",
       " ('android', 565),\n",
       " ('pop', 543),\n",
       " ('network', 447),\n",
       " ('via', 400),\n",
       " ('line', 391),\n",
       " ('get', 383),\n",
       " ('free', 378),\n",
       " ('called', 353),\n",
       " ('mobile', 342),\n",
       " ('party', 335),\n",
       " ('sxswi', 333),\n",
       " ('major', 301),\n",
       " ('one', 297),\n",
       " ('like', 275),\n",
       " ('time', 262),\n",
       " ('w', 261),\n",
       " ('check', 257),\n",
       " ('temporary', 254),\n",
       " ('opening', 242),\n",
       " ('possibly', 240),\n",
       " ('day', 231),\n",
       " ('people', 223),\n",
       " ('see', 217),\n",
       " ('downtown', 216),\n",
       " ('mayer', 212),\n",
       " ('great', 211),\n",
       " ('going', 211),\n",
       " ('maps', 211),\n",
       " ('apps', 210),\n",
       " ('go', 203),\n",
       " ('popup', 198),\n",
       " ('need', 196)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = FreqDist()\n",
    "for tweet in data_df['tweet_text'].map(lambda x:doc_preparer(x,stem=False)):\n",
    "    for word in tweet.split():\n",
    "        word_freq[word] +=1\n",
    "word_freq.most_common(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ccffee",
   "metadata": {},
   "source": [
    "Adding venue specific words and twitter specific words to stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bc3a00b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:36.606868Z",
     "start_time": "2022-05-09T05:46:36.591857Z"
    }
   },
   "outputs": [],
   "source": [
    "#Maybe don't add mention? and link?\n",
    "sw.extend(['sxsw','rt','quot','austin','sxswi','mention','link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed540e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:38.773362Z",
     "start_time": "2022-05-09T05:46:36.607869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ipad', 2935),\n",
       " ('googl', 2508),\n",
       " ('appl', 2187),\n",
       " ('iphon', 1505),\n",
       " ('store', 1437),\n",
       " ('new', 1057),\n",
       " ('app', 1002),\n",
       " ('amp', 803),\n",
       " ('launch', 802),\n",
       " ('circl', 654),\n",
       " ('social', 637),\n",
       " ('today', 566),\n",
       " ('android', 565),\n",
       " ('pop', 558),\n",
       " ('get', 514),\n",
       " ('open', 498),\n",
       " ('network', 468),\n",
       " ('line', 440),\n",
       " ('go', 416),\n",
       " ('via', 400),\n",
       " ('call', 389),\n",
       " ('parti', 387),\n",
       " ('free', 378),\n",
       " ('mobil', 345),\n",
       " ('come', 326),\n",
       " ('like', 309),\n",
       " ('use', 309),\n",
       " ('major', 306),\n",
       " ('win', 305),\n",
       " ('time', 304),\n",
       " ('one', 301),\n",
       " ('check', 300),\n",
       " ('day', 280),\n",
       " ('map', 264),\n",
       " ('w', 261),\n",
       " ('possibl', 254),\n",
       " ('temporari', 254),\n",
       " ('see', 250),\n",
       " ('need', 238),\n",
       " ('look', 228),\n",
       " ('design', 225),\n",
       " ('peopl', 223),\n",
       " ('make', 219),\n",
       " ('downtown', 216),\n",
       " ('mayer', 213),\n",
       " ('great', 211),\n",
       " ('popup', 199),\n",
       " ('know', 196),\n",
       " ('marissa', 186),\n",
       " ('talk', 184)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = FreqDist()\n",
    "for tweet in data_df['tweet_text'].map(lambda x:doc_preparer(x,stem=True)):\n",
    "    for word in tweet.split():\n",
    "        word_freq[word] +=1\n",
    "word_freq.most_common(n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e4fd93a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:40.973598Z",
     "start_time": "2022-05-09T05:46:38.774362Z"
    }
   },
   "outputs": [],
   "source": [
    "data_df['stemmed_tokens'] = data_df['tweet_text'].map(lambda x:doc_preparer(x,stem=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfb76f15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:40.989604Z",
     "start_time": "2022-05-09T05:46:40.974599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley g iphon hr tweet rise dead need upgrad plugin station</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessede know fludapp awesom ipad iphon app like appreci design also give free ts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festiv crashi year iphon app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri marissa mayer googl tim reilli tech book confer amp matt mullenweg wordpress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ipad everywher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>wave buzz interrupt regularli schedul geek program big news googl circl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>googl zeiger physician never report potenti ae yet fda reli physician oper w data health dev</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>verizon iphon custom complain time fell back hour weekend cours new yorker attend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mention Google Tests ���Check-in Offers�۝ At #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>googl test check offer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8569 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "8716                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "8717                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "8718  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "8719       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "8720                                                  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mention Google Tests ���Check-in Offers�۝ At #SXSW {link}   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "8716                            iPad   \n",
       "8717                             NaN   \n",
       "8718                             NaN   \n",
       "8719                             NaN   \n",
       "8720                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                      Negative emotion   \n",
       "1                                      Positive emotion   \n",
       "2                                      Positive emotion   \n",
       "3                                      Negative emotion   \n",
       "4                                      Positive emotion   \n",
       "...                                                 ...   \n",
       "8716                                   Positive emotion   \n",
       "8717                 No emotion toward brand or product   \n",
       "8718                 No emotion toward brand or product   \n",
       "8719                 No emotion toward brand or product   \n",
       "8720                 No emotion toward brand or product   \n",
       "\n",
       "                                                                                              stemmed_tokens  \n",
       "0                                               wesley g iphon hr tweet rise dead need upgrad plugin station  \n",
       "1                           jessede know fludapp awesom ipad iphon app like appreci design also give free ts  \n",
       "2                                                                             swonderlin wait ipad also sale  \n",
       "3                                                                     hope year festiv crashi year iphon app  \n",
       "4     sxtxstate great stuff fri marissa mayer googl tim reilli tech book confer amp matt mullenweg wordpress  \n",
       "...                                                                                                      ...  \n",
       "8716                                                                                          ipad everywher  \n",
       "8717                                 wave buzz interrupt regularli schedul geek program big news googl circl  \n",
       "8718            googl zeiger physician never report potenti ae yet fda reli physician oper w data health dev  \n",
       "8719                       verizon iphon custom complain time fell back hour weekend cours new yorker attend  \n",
       "8720                                                                                  googl test check offer  \n",
       "\n",
       "[8569 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3baaef",
   "metadata": {},
   "source": [
    "# Label Encoding the sentinment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c279ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:41.005608Z",
     "start_time": "2022-05-09T05:46:40.993605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'No emotion toward brand or product',\n",
       "       'Positive emotion'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "data_df['sentiment_target'] = le.fit_transform(data_df.is_there_an_emotion_directed_at_a_brand_or_product)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6903ec0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:41.021611Z",
     "start_time": "2022-05-09T05:46:41.006607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>sentiment_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley g iphon hr tweet rise dead need upgrad plugin station</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessede know fludapp awesom ipad iphon app like appreci design also give free ts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin wait ipad also sale</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>hope year festiv crashi year iphon app</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp;amp; Matt Mullenweg (Wordpress)</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff fri marissa mayer googl tim reilli tech book confer amp matt mullenweg wordpress</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8716</th>\n",
       "      <td>Ipad everywhere. #SXSW {link}</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>ipad everywher</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>wave buzz interrupt regularli schedul geek program big news googl circl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8718</th>\n",
       "      <td>Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &amp;quot;We're operating w/out data.&amp;quot; #sxsw #health2dev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>googl zeiger physician never report potenti ae yet fda reli physician oper w data health dev</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8719</th>\n",
       "      <td>Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>verizon iphon custom complain time fell back hour weekend cours new yorker attend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>�ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mention Google Tests ���Check-in Offers�۝ At #SXSW {link}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>googl test check offer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8569 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             tweet_text  \\\n",
       "0                       .@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.   \n",
       "1           @jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW   \n",
       "2                                                                       @swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.   \n",
       "3                                                                    @sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw   \n",
       "4                   @sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)   \n",
       "...                                                                                                                                                 ...   \n",
       "8716                                                                                                                      Ipad everywhere. #SXSW {link}   \n",
       "8717                      Wave, buzz... RT @mention We interrupt your regularly scheduled #sxsw geek programming with big news {link}  #google #circles   \n",
       "8718  Google's Zeiger, a physician never reported potential AE. Yet FDA relies on physicians. &quot;We're operating w/out data.&quot; #sxsw #health2dev   \n",
       "8719       Some Verizon iPhone customers complained their time fell back an hour this weekend.  Of course they were the New Yorkers who attended #SXSW.   \n",
       "8720                                                  �ϡ�����_��ʋ�΋�ҋ�������⋁_��������_���RT @mention Google Tests ���Check-in Offers�۝ At #SXSW {link}   \n",
       "\n",
       "     emotion_in_tweet_is_directed_at  \\\n",
       "0                             iPhone   \n",
       "1                 iPad or iPhone App   \n",
       "2                               iPad   \n",
       "3                 iPad or iPhone App   \n",
       "4                             Google   \n",
       "...                              ...   \n",
       "8716                            iPad   \n",
       "8717                             NaN   \n",
       "8718                             NaN   \n",
       "8719                             NaN   \n",
       "8720                             NaN   \n",
       "\n",
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                      Negative emotion   \n",
       "1                                      Positive emotion   \n",
       "2                                      Positive emotion   \n",
       "3                                      Negative emotion   \n",
       "4                                      Positive emotion   \n",
       "...                                                 ...   \n",
       "8716                                   Positive emotion   \n",
       "8717                 No emotion toward brand or product   \n",
       "8718                 No emotion toward brand or product   \n",
       "8719                 No emotion toward brand or product   \n",
       "8720                 No emotion toward brand or product   \n",
       "\n",
       "                                                                                              stemmed_tokens  \\\n",
       "0                                               wesley g iphon hr tweet rise dead need upgrad plugin station   \n",
       "1                           jessede know fludapp awesom ipad iphon app like appreci design also give free ts   \n",
       "2                                                                             swonderlin wait ipad also sale   \n",
       "3                                                                     hope year festiv crashi year iphon app   \n",
       "4     sxtxstate great stuff fri marissa mayer googl tim reilli tech book confer amp matt mullenweg wordpress   \n",
       "...                                                                                                      ...   \n",
       "8716                                                                                          ipad everywher   \n",
       "8717                                 wave buzz interrupt regularli schedul geek program big news googl circl   \n",
       "8718            googl zeiger physician never report potenti ae yet fda reli physician oper w data health dev   \n",
       "8719                       verizon iphon custom complain time fell back hour weekend cours new yorker attend   \n",
       "8720                                                                                  googl test check offer   \n",
       "\n",
       "      sentiment_target  \n",
       "0                    0  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    0  \n",
       "4                    2  \n",
       "...                ...  \n",
       "8716                 2  \n",
       "8717                 1  \n",
       "8718                 1  \n",
       "8719                 1  \n",
       "8720                 1  \n",
       "\n",
       "[8569 rows x 5 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a57a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76321443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6adb46d4",
   "metadata": {},
   "source": [
    "# Define X,y, train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe31240d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:41.037615Z",
     "start_time": "2022-05-09T05:46:41.022612Z"
    }
   },
   "outputs": [],
   "source": [
    "X = data_df['stemmed_tokens']\n",
    "y = data_df['sentiment_target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ca071c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:41.053618Z",
     "start_time": "2022-05-09T05:46:41.038615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6866"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42635827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96025cae",
   "metadata": {},
   "source": [
    "# CountVec with MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e36304c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:41.210657Z",
     "start_time": "2022-05-09T05:46:41.054619Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer()\n",
    "\n",
    "X_train_vec = cvec.fit_transform(X_train)\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_train_vec.columns = sorted(cvec.vocabulary_)\n",
    "X_train_vec.set_index(y_train.index, inplace=True)\n",
    "# X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb885734",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:56:50.780733Z",
     "start_time": "2022-05-09T05:56:46.854008Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.753\n",
      "Test accuracy:     0.661\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.494\n",
      "Test F1 score:     0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "cvec_mnb_cvResults = cross_validate(mnb,\n",
    "                                      X_train_vec,\n",
    "                                      y_train,\n",
    "                                      scoring=('accuracy', 'f1_macro'),\n",
    "                                      cv=5,\n",
    "                                      verbose=1,\n",
    "                                      n_jobs = -2,\n",
    "                                      return_train_score=True)\n",
    "\n",
    "cv_printScores(cvec_mnb_cvResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9053e23",
   "metadata": {},
   "source": [
    "# TiffyDiffy with MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2356535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:46.764352Z",
     "start_time": "2022-05-09T05:46:46.559545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = tvec.fit_transform(X_train)\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_train_vec.columns = sorted(tvec.vocabulary_)\n",
    "X_train_vec.set_index(y_train.index, inplace=True)\n",
    "# X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1641a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:56:45.359706Z",
     "start_time": "2022-05-09T05:56:41.568354Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.753\n",
      "Test accuracy:     0.661\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.494\n",
      "Test F1 score:     0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "tvec_mnb_cvResults = cross_validate(mnb,\n",
    "                                      X_train_vec,\n",
    "                                      y_train,\n",
    "                                      scoring=('accuracy', 'f1_macro'),\n",
    "                                      cv=5,\n",
    "                                      verbose=1,\n",
    "                                      n_jobs = -2,\n",
    "                                      return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_mnb_cvResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c219744",
   "metadata": {},
   "source": [
    "# TiffyDiffy with RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0a643d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:46:52.152687Z",
     "start_time": "2022-05-09T05:46:51.951931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = tvec.fit_transform(X_train)\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_train_vec.columns = sorted(tvec.vocabulary_)\n",
    "X_train_vec.set_index(y_train.index, inplace=True)\n",
    "# X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "188c910a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:56:40.059796Z",
     "start_time": "2022-05-09T05:56:28.805685Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.968\n",
      "Test accuracy:     0.683\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.967\n",
      "Test F1 score:     0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   11.1s finished\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "tvec_rfc_cvResults = cross_validate(rfc,\n",
    "                                    X_train_vec,\n",
    "                                    y_train,\n",
    "                                    scoring=('accuracy', 'f1_macro'),\n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=-2,\n",
    "                                    return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_rfc_cvResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed564ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:54:03.827301Z",
     "start_time": "2022-05-09T05:52:07.042444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vec', TfidfVectorizer()),\n",
       "                                       ('rfc',\n",
       "                                        RandomForestClassifier(n_jobs=-2,\n",
       "                                                               random_state=42))]),\n",
       "             n_jobs=-2,\n",
       "             param_grid={'rfc__criterion': ['gini', 'entropy'],\n",
       "                         'rfc__max_depth': array([150, 160, 170, 180, 190]),\n",
       "                         'rfc__n_estimators': array([ 50, 100, 150, 200, 250])},\n",
       "             refit='accuracy', return_train_score=True,\n",
       "             scoring=['accuracy', 'precision_macro', 'recall_macro',\n",
       "                      'f1_macro'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {}\n",
    "params['rfc__criterion'] = ['gini','entropy']\n",
    "params['rfc__n_estimators'] = np.arange(50,300,50)\n",
    "params['rfc__max_depth'] = np.arange(150,200,10)\n",
    "# params['rfc__max_leaf_nodes']=[4000,4500,5000]\n",
    "\n",
    "rfc_model_pipe = Pipeline([\n",
    "    ('vec',TfidfVectorizer()),\n",
    "   ('rfc',RandomForestClassifier(random_state=42,n_jobs=-2))\n",
    "])\n",
    "\n",
    "rfc_gs1 = GridSearchCV(estimator=rfc_model_pipe,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           n_jobs=-2,\n",
    "                           scoring=[ 'accuracy','precision_macro','recall_macro','f1_macro'],\n",
    "                           refit='accuracy',\n",
    "                           return_train_score=True)\n",
    "\n",
    "rfc_gs1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd30b9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:54:05.348471Z",
     "start_time": "2022-05-09T05:54:05.318465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Test Accuracy</th>\n",
       "      <th>Mean Test Precision (macro)</th>\n",
       "      <th>Mean Test Recall (macro)</th>\n",
       "      <th>Mean Test F1-Score (macro)</th>\n",
       "      <th>param_rfc__criterion</th>\n",
       "      <th>param_rfc__max_depth</th>\n",
       "      <th>param_rfc__n_estimators</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank (By Accuracy)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6906</td>\n",
       "      <td>0.7043</td>\n",
       "      <td>0.4961</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>gini</td>\n",
       "      <td>160</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6897</td>\n",
       "      <td>0.6991</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6896</td>\n",
       "      <td>0.7022</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.5227</td>\n",
       "      <td>gini</td>\n",
       "      <td>160</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6891</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.4949</td>\n",
       "      <td>0.5221</td>\n",
       "      <td>entropy</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>0.4951</td>\n",
       "      <td>0.5230</td>\n",
       "      <td>gini</td>\n",
       "      <td>190</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6887</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.4946</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>entropy</td>\n",
       "      <td>190</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6888</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.5206</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.4955</td>\n",
       "      <td>0.5233</td>\n",
       "      <td>entropy</td>\n",
       "      <td>170</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6886</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>entropy</td>\n",
       "      <td>170</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6884</td>\n",
       "      <td>0.7018</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>gini</td>\n",
       "      <td>160</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.5201</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.6951</td>\n",
       "      <td>0.4934</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.4954</td>\n",
       "      <td>0.5235</td>\n",
       "      <td>gini</td>\n",
       "      <td>180</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.6879</td>\n",
       "      <td>0.6865</td>\n",
       "      <td>0.4959</td>\n",
       "      <td>0.5239</td>\n",
       "      <td>gini</td>\n",
       "      <td>180</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.6895</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.5204</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.6876</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>gini</td>\n",
       "      <td>170</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.6874</td>\n",
       "      <td>0.6883</td>\n",
       "      <td>0.4938</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>gini</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.4935</td>\n",
       "      <td>0.5212</td>\n",
       "      <td>gini</td>\n",
       "      <td>170</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.6850</td>\n",
       "      <td>0.4947</td>\n",
       "      <td>0.5228</td>\n",
       "      <td>entropy</td>\n",
       "      <td>170</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>gini</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>0.5210</td>\n",
       "      <td>gini</td>\n",
       "      <td>170</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.4909</td>\n",
       "      <td>0.5178</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.6866</td>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>0.5200</td>\n",
       "      <td>entropy</td>\n",
       "      <td>190</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>0.5203</td>\n",
       "      <td>gini</td>\n",
       "      <td>190</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>0.5194</td>\n",
       "      <td>entropy</td>\n",
       "      <td>160</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.4941</td>\n",
       "      <td>0.5222</td>\n",
       "      <td>gini</td>\n",
       "      <td>180</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.6861</td>\n",
       "      <td>0.6983</td>\n",
       "      <td>0.4923</td>\n",
       "      <td>0.5202</td>\n",
       "      <td>gini</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>gini</td>\n",
       "      <td>190</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.6840</td>\n",
       "      <td>0.4905</td>\n",
       "      <td>0.5174</td>\n",
       "      <td>entropy</td>\n",
       "      <td>160</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.6917</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.6849</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>0.4935</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>entropy</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.6847</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>0.4916</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>entropy</td>\n",
       "      <td>180</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.4914</td>\n",
       "      <td>0.5185</td>\n",
       "      <td>entropy</td>\n",
       "      <td>190</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.6844</td>\n",
       "      <td>0.6929</td>\n",
       "      <td>0.4898</td>\n",
       "      <td>0.5170</td>\n",
       "      <td>gini</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>0.4906</td>\n",
       "      <td>0.5175</td>\n",
       "      <td>gini</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.6841</td>\n",
       "      <td>0.6777</td>\n",
       "      <td>0.4913</td>\n",
       "      <td>0.5181</td>\n",
       "      <td>entropy</td>\n",
       "      <td>180</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.5198</td>\n",
       "      <td>entropy</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.6836</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>0.5195</td>\n",
       "      <td>entropy</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.6834</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.5186</td>\n",
       "      <td>gini</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.6834</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.4936</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>entropy</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.6831</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.5184</td>\n",
       "      <td>entropy</td>\n",
       "      <td>190</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.6829</td>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.4889</td>\n",
       "      <td>0.5157</td>\n",
       "      <td>entropy</td>\n",
       "      <td>160</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.6827</td>\n",
       "      <td>0.6740</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>0.5165</td>\n",
       "      <td>entropy</td>\n",
       "      <td>180</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.6821</td>\n",
       "      <td>0.6864</td>\n",
       "      <td>0.4901</td>\n",
       "      <td>0.5176</td>\n",
       "      <td>gini</td>\n",
       "      <td>180</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.6821</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>entropy</td>\n",
       "      <td>160</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.6819</td>\n",
       "      <td>0.6779</td>\n",
       "      <td>0.4903</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>entropy</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.6835</td>\n",
       "      <td>0.4897</td>\n",
       "      <td>0.5169</td>\n",
       "      <td>gini</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.4911</td>\n",
       "      <td>0.5189</td>\n",
       "      <td>entropy</td>\n",
       "      <td>190</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.6812</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>0.4874</td>\n",
       "      <td>0.5136</td>\n",
       "      <td>gini</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Mean Test Accuracy Mean Test Precision (macro)  \\\n",
       "Rank (By Accuracy)                                                  \n",
       "1                              0.6906                      0.7043   \n",
       "2                              0.6897                      0.6991   \n",
       "3                              0.6896                      0.7022   \n",
       "4                              0.6891                      0.6858   \n",
       "5                              0.6887                      0.6901   \n",
       "5                              0.6887                      0.6858   \n",
       "7                              0.6886                      0.6888   \n",
       "8                              0.6886                      0.6849   \n",
       "9                              0.6886                      0.6851   \n",
       "10                             0.6884                      0.7018   \n",
       "11                             0.6881                      0.6979   \n",
       "12                             0.6881                      0.6951   \n",
       "13                             0.6879                      0.6900   \n",
       "14                             0.6879                      0.6865   \n",
       "15                             0.6876                      0.6895   \n",
       "16                             0.6876                      0.6904   \n",
       "17                             0.6874                      0.6883   \n",
       "18                             0.6871                      0.6919   \n",
       "19                             0.6871                      0.6850   \n",
       "20                             0.6869                      0.7028   \n",
       "21                             0.6867                      0.6893   \n",
       "22                             0.6867                      0.6861   \n",
       "23                             0.6866                      0.6808   \n",
       "24                             0.6862                      0.6864   \n",
       "25                             0.6862                      0.6861   \n",
       "26                             0.6862                      0.6846   \n",
       "27                             0.6861                      0.6862   \n",
       "28                             0.6861                      0.6983   \n",
       "29                             0.6859                      0.6843   \n",
       "30                             0.6856                      0.6840   \n",
       "31                             0.6849                      0.6917   \n",
       "32                             0.6849                      0.6930   \n",
       "33                             0.6847                      0.6761   \n",
       "34                             0.6844                      0.6800   \n",
       "35                             0.6844                      0.6929   \n",
       "36                             0.6842                      0.6827   \n",
       "37                             0.6841                      0.6777   \n",
       "38                             0.6837                      0.6770   \n",
       "39                             0.6836                      0.6818   \n",
       "40                             0.6834                      0.6843   \n",
       "41                             0.6834                      0.6790   \n",
       "42                             0.6831                      0.6811   \n",
       "43                             0.6829                      0.6812   \n",
       "44                             0.6827                      0.6740   \n",
       "45                             0.6821                      0.6864   \n",
       "46                             0.6821                      0.6773   \n",
       "47                             0.6819                      0.6779   \n",
       "48                             0.6812                      0.6835   \n",
       "49                             0.6812                      0.6818   \n",
       "50                             0.6812                      0.6837   \n",
       "\n",
       "                   Mean Test Recall (macro) Mean Test F1-Score (macro)  \\\n",
       "Rank (By Accuracy)                                                       \n",
       "1                                    0.4961                     0.5247   \n",
       "2                                    0.4939                     0.5215   \n",
       "3                                    0.4946                     0.5227   \n",
       "4                                    0.4949                     0.5221   \n",
       "5                                    0.4951                     0.5230   \n",
       "5                                    0.4946                     0.5218   \n",
       "7                                    0.4933                     0.5206   \n",
       "8                                    0.4955                     0.5233   \n",
       "9                                    0.4965                     0.5249   \n",
       "10                                   0.4940                     0.5225   \n",
       "11                                   0.4926                     0.5201   \n",
       "12                                   0.4934                     0.5213   \n",
       "13                                   0.4954                     0.5235   \n",
       "14                                   0.4959                     0.5239   \n",
       "15                                   0.4928                     0.5204   \n",
       "16                                   0.4937                     0.5214   \n",
       "17                                   0.4938                     0.5215   \n",
       "18                                   0.4935                     0.5212   \n",
       "19                                   0.4947                     0.5228   \n",
       "20                                   0.4907                     0.5178   \n",
       "21                                   0.4933                     0.5210   \n",
       "22                                   0.4909                     0.5178   \n",
       "23                                   0.4930                     0.5200   \n",
       "24                                   0.4907                     0.5176   \n",
       "25                                   0.4930                     0.5203   \n",
       "26                                   0.4920                     0.5194   \n",
       "27                                   0.4941                     0.5222   \n",
       "28                                   0.4923                     0.5202   \n",
       "29                                   0.4922                     0.5192   \n",
       "30                                   0.4905                     0.5174   \n",
       "31                                   0.4901                     0.5170   \n",
       "32                                   0.4935                     0.5218   \n",
       "33                                   0.4916                     0.5185   \n",
       "34                                   0.4914                     0.5185   \n",
       "35                                   0.4898                     0.5170   \n",
       "36                                   0.4906                     0.5175   \n",
       "37                                   0.4913                     0.5181   \n",
       "38                                   0.4926                     0.5198   \n",
       "39                                   0.4922                     0.5195   \n",
       "40                                   0.4911                     0.5186   \n",
       "41                                   0.4936                     0.5215   \n",
       "42                                   0.4911                     0.5184   \n",
       "43                                   0.4889                     0.5157   \n",
       "44                                   0.4899                     0.5165   \n",
       "45                                   0.4901                     0.5176   \n",
       "46                                   0.4897                     0.5166   \n",
       "47                                   0.4903                     0.5173   \n",
       "48                                   0.4897                     0.5169   \n",
       "49                                   0.4911                     0.5189   \n",
       "50                                   0.4874                     0.5136   \n",
       "\n",
       "                   param_rfc__criterion param_rfc__max_depth  \\\n",
       "Rank (By Accuracy)                                             \n",
       "1                                  gini                  160   \n",
       "2                                  gini                  150   \n",
       "3                                  gini                  160   \n",
       "4                               entropy                  170   \n",
       "5                                  gini                  190   \n",
       "5                               entropy                  190   \n",
       "7                               entropy                  150   \n",
       "8                               entropy                  170   \n",
       "9                               entropy                  170   \n",
       "10                                 gini                  160   \n",
       "11                                 gini                  150   \n",
       "12                                 gini                  150   \n",
       "13                                 gini                  180   \n",
       "14                                 gini                  180   \n",
       "15                              entropy                  150   \n",
       "16                                 gini                  170   \n",
       "17                                 gini                  170   \n",
       "18                                 gini                  170   \n",
       "19                              entropy                  170   \n",
       "20                                 gini                  160   \n",
       "21                                 gini                  170   \n",
       "22                              entropy                  150   \n",
       "23                              entropy                  190   \n",
       "24                              entropy                  150   \n",
       "25                                 gini                  190   \n",
       "26                              entropy                  160   \n",
       "27                                 gini                  180   \n",
       "28                                 gini                  160   \n",
       "29                                 gini                  190   \n",
       "30                              entropy                  160   \n",
       "31                                 gini                  150   \n",
       "32                              entropy                  150   \n",
       "33                              entropy                  180   \n",
       "34                              entropy                  190   \n",
       "35                                 gini                  150   \n",
       "36                                 gini                  190   \n",
       "37                              entropy                  180   \n",
       "38                              entropy                  170   \n",
       "39                              entropy                  160   \n",
       "40                                 gini                  180   \n",
       "41                              entropy                  180   \n",
       "42                              entropy                  190   \n",
       "43                              entropy                  160   \n",
       "44                              entropy                  180   \n",
       "45                                 gini                  180   \n",
       "46                              entropy                  160   \n",
       "47                              entropy                  180   \n",
       "48                                 gini                  190   \n",
       "49                              entropy                  190   \n",
       "50                                 gini                  170   \n",
       "\n",
       "                   param_rfc__n_estimators  \n",
       "Rank (By Accuracy)                          \n",
       "1                                      250  \n",
       "2                                      200  \n",
       "3                                      200  \n",
       "4                                      100  \n",
       "5                                      250  \n",
       "5                                      150  \n",
       "7                                      200  \n",
       "8                                      150  \n",
       "9                                      250  \n",
       "10                                     150  \n",
       "11                                     250  \n",
       "12                                     150  \n",
       "13                                     250  \n",
       "14                                     200  \n",
       "15                                     250  \n",
       "16                                     100  \n",
       "17                                     200  \n",
       "18                                     250  \n",
       "19                                     200  \n",
       "20                                      50  \n",
       "21                                     150  \n",
       "22                                     150  \n",
       "23                                     200  \n",
       "24                                     100  \n",
       "25                                     200  \n",
       "26                                     250  \n",
       "27                                     150  \n",
       "28                                     100  \n",
       "29                                     150  \n",
       "30                                     200  \n",
       "31                                      50  \n",
       "32                                      50  \n",
       "33                                     150  \n",
       "34                                     250  \n",
       "35                                     100  \n",
       "36                                     100  \n",
       "37                                     200  \n",
       "38                                      50  \n",
       "39                                      50  \n",
       "40                                     100  \n",
       "41                                      50  \n",
       "42                                     100  \n",
       "43                                     150  \n",
       "44                                     250  \n",
       "45                                      50  \n",
       "46                                     100  \n",
       "47                                     100  \n",
       "48                                      50  \n",
       "49                                      50  \n",
       "50                                      50  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettyPrintGridCVResults(rfc_gs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e4632b",
   "metadata": {},
   "source": [
    "# TiffyDiffy with GradientBoosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eeda90aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:54:06.973795Z",
     "start_time": "2022-05-09T05:54:06.848546Z"
    }
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = tvec.fit_transform(X_train)\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(X_train_vec)\n",
    "X_train_vec.columns = sorted(tvec.vocabulary_)\n",
    "X_train_vec.set_index(y_train.index, inplace=True)\n",
    "# X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ba3b1f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T05:56:27.309253Z",
     "start_time": "2022-05-09T05:56:13.259104Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 15 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.736\n",
      "Test accuracy:     0.667\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.578\n",
      "Test F1 score:     0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:   13.9s finished\n"
     ]
    }
   ],
   "source": [
    "grad = GradientBoostingClassifier()\n",
    "\n",
    "tvec_grad_cvResults = cross_validate(grad,\n",
    "                                      X_train_vec,\n",
    "                                      y_train,\n",
    "                                      scoring=('accuracy', 'f1_macro'),\n",
    "                                      cv=5,\n",
    "                                      verbose=1,\n",
    "                                      n_jobs = -2,\n",
    "                                      return_train_score=True)\n",
    "\n",
    "cv_printScores(tvec_grad_cvResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc0c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6126662e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
